# Custom Konkani Sentiment Analysis Model

## ğŸ¯ Overview

This is a **completely custom neural network** built from scratch using PyTorch for Konkani sentiment analysis. Unlike transfer learning approaches, this model is designed specifically for Konkani language with a custom architecture.

## ğŸ—ï¸ Architecture

### Model Components:

```
Input Text
    â†“
Custom Tokenizer (10K vocab)
    â†“
Embedding Layer (256 dim)
    â†“
Bidirectional LSTM (2 layers, 256 hidden units)
    â†“
Attention Mechanism
    â†“
Fully Connected Layer (256 â†’ 3)
    â†“
Softmax â†’ [Negative, Neutral, Positive]
```

### Key Features:

1. **Custom Tokenizer**: Built specifically for Konkani (Devanagari + Roman)
2. **BiLSTM**: Captures context from both directions
3. **Attention Mechanism**: Focuses on important words
4. **Dropout**: Prevents overfitting (30%)
5. **Total Parameters**: ~3-5 million (lightweight!)

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
# Activate virtual environment
source .venv/bin/activate

# Install PyTorch and dependencies
pip install torch pandas numpy scikit-learn matplotlib seaborn tqdm
```

### 2. Train the Model

```bash
python train_custom_model.py
```

**Training Time:**
- CPU: 1-2 hours
- GPU: 15-30 minutes
- Apple Silicon (MPS): 20-40 minutes

### 3. Test the Model

```bash
python test_custom_model.py
```

## ğŸ“Š Model Specifications

| Component | Details |
|-----------|---------|
| **Architecture** | BiLSTM + Attention |
| **Vocabulary Size** | 10,000 words |
| **Embedding Dimension** | 256 |
| **Hidden Dimension** | 256 |
| **LSTM Layers** | 2 (Bidirectional) |
| **Total Parameters** | ~3-5M |
| **Trainable Parameters** | ~3-5M |
| **Input Length** | Max 128 tokens |
| **Output Classes** | 3 (Negative, Neutral, Positive) |

## ğŸ“ Training Configuration

### Default Hyperparameters:

```python
VOCAB_SIZE = 10000        # Vocabulary size
EMBEDDING_DIM = 256       # Word embedding dimension
HIDDEN_DIM = 256          # LSTM hidden dimension
NUM_LAYERS = 2            # Number of LSTM layers
DROPOUT = 0.3             # Dropout rate
BATCH_SIZE = 32           # Training batch size
NUM_EPOCHS = 15           # Maximum epochs
LEARNING_RATE = 0.001     # Initial learning rate
MAX_LENGTH = 128          # Maximum sequence length
```

### Training Features:

- âœ… **Early Stopping**: Stops if no improvement for 3 epochs
- âœ… **Learning Rate Scheduling**: Reduces LR on plateau
- âœ… **Gradient Clipping**: Prevents exploding gradients
- âœ… **Automatic Device Selection**: GPU/MPS/CPU
- âœ… **Progress Bars**: Real-time training monitoring
- âœ… **Checkpointing**: Saves best model automatically

## ğŸ“ˆ Expected Performance

Based on your 47,922 entry dataset:

| Metric | Expected Range |
|--------|---------------|
| **Accuracy** | 82-88% |
| **F1 Score** | 0.80-0.86 |
| **Precision** | 0.79-0.85 |
| **Recall** | 0.81-0.87 |

## ğŸ“ Output Files

After training, you'll find:

```
custom_konkani_model/
â”œâ”€â”€ best_model.pt           # Best model checkpoint
â”œâ”€â”€ final_model.pt          # Final model checkpoint
â”œâ”€â”€ tokenizer.pkl           # Custom tokenizer
â”œâ”€â”€ model_info.json         # Model metadata
â”œâ”€â”€ test_results.json       # Test metrics
â”œâ”€â”€ training_history.png    # Loss/accuracy plots
â””â”€â”€ confusion_matrix.png    # Confusion matrix
```

## ğŸ’» Usage Examples

### Python API

```python
from test_custom_model import KonkaniSentimentPredictor

# Load model
predictor = KonkaniSentimentPredictor("./custom_konkani_model")

# Predict single sentence
result = predictor.predict("à¤¹à¥‡à¤‚ à¤«à¥‹à¤¨ à¤–à¥‚à¤¬ à¤›à¤¾à¤¨ à¤†à¤¸à¤¾")
print(result)
# {
#   'label': 'positive',
#   'emoji': 'ğŸ˜Š',
#   'confidence': 0.92,
#   'probabilities': {
#     'negative': 0.03,
#     'neutral': 0.05,
#     'positive': 0.92
#   }
# }

# Batch prediction
sentences = [
    "à¤¹à¥‡à¤‚ à¤«à¥‹à¤¨ à¤–à¥‚à¤¬ à¤›à¤¾à¤¨ à¤†à¤¸à¤¾",
    "à¤¹à¥€ à¤¸à¥‡à¤µà¤¾ à¤µà¤¾à¤¯à¤Ÿ à¤†à¤¸à¤¾",
    "à¤¹à¥‡à¤‚ à¤ªà¥à¤¸à¥à¤¤à¤• à¤¸à¤¾à¤§à¤¾à¤°à¤£ à¤†à¤¸à¤¾"
]

for sentence in sentences:
    result = predictor.predict(sentence)
    print(f"{sentence} â†’ {result['label']} ({result['confidence']:.2%})")
```

### Command Line

```bash
# Interactive mode
python test_custom_model.py

# With custom model path
python test_custom_model.py /path/to/model
```

## ğŸ”§ Customization

### Adjust Model Size

For **faster training** (smaller model):
```python
EMBEDDING_DIM = 128
HIDDEN_DIM = 128
NUM_LAYERS = 1
```

For **better accuracy** (larger model):
```python
EMBEDDING_DIM = 512
HIDDEN_DIM = 512
NUM_LAYERS = 3
VOCAB_SIZE = 20000
```

### Change Architecture

You can modify the model in `train_custom_model.py`:

```python
# Add more LSTM layers
NUM_LAYERS = 3

# Increase vocabulary
VOCAB_SIZE = 15000

# Longer sequences
MAX_LENGTH = 256

# Different dropout
DROPOUT = 0.5
```

## ğŸ†š Comparison: Custom vs Transfer Learning

| Aspect | Custom Model | Transfer Learning (BERT) |
|--------|--------------|--------------------------|
| **Parameters** | 3-5M | 110M+ |
| **Training Time** | 1-2 hours | 2-4 hours |
| **Inference Speed** | Very Fast | Moderate |
| **Memory Usage** | Low (< 1GB) | High (> 4GB) |
| **Accuracy** | 82-88% | 85-92% |
| **Customization** | Full Control | Limited |
| **Konkani-Specific** | Yes | No |

## ğŸ¯ Advantages of Custom Model

1. **Lightweight**: 20-30x smaller than BERT
2. **Fast Inference**: 5-10x faster predictions
3. **Low Memory**: Runs on any device
4. **Full Control**: Customize every layer
5. **Konkani-Optimized**: Built for your specific data
6. **Interpretable**: Attention weights show what matters
7. **No Dependencies**: Just PyTorch needed

## ğŸ“Š Monitoring Training

The training script provides real-time feedback:

```
Epoch 1/15
------------------------------------------------------------
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1061/1061 [02:15<00:00, 7.83it/s, loss=0.8234, acc=0.6521]
Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 227/227 [00:18<00:00, 12.45it/s, loss=0.7123, acc=0.7012]
Train Loss: 0.8234 | Train Acc: 0.6521
Val Loss: 0.7123 | Val Acc: 0.7012
âœ“ Saved best model
```

## ğŸ› Troubleshooting

### Out of Memory

```python
# Reduce batch size
BATCH_SIZE = 16  # or 8

# Reduce model size
HIDDEN_DIM = 128
EMBEDDING_DIM = 128
```

### Slow Training

```python
# Use GPU if available (automatic)
# Or reduce model complexity
NUM_LAYERS = 1
VOCAB_SIZE = 5000
```

### Overfitting

```python
# Increase dropout
DROPOUT = 0.5

# Add more regularization
# (modify optimizer in train_custom_model.py)
optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)
```

### Underfitting

```python
# Increase model capacity
HIDDEN_DIM = 512
NUM_LAYERS = 3

# Train longer
NUM_EPOCHS = 25

# Lower learning rate
LEARNING_RATE = 0.0005
```

## ğŸ“š Understanding the Architecture

### 1. Custom Tokenizer
- Builds vocabulary from your data
- Handles both Devanagari and Roman scripts
- Special tokens: `<PAD>`, `<UNK>`, `<START>`, `<END>`

### 2. Embedding Layer
- Converts words to dense vectors
- Learns word representations during training
- 256-dimensional embeddings

### 3. BiLSTM
- Processes text in both directions
- Captures long-range dependencies
- 2 layers with 256 hidden units each

### 4. Attention Mechanism
- Identifies important words
- Weighted sum of LSTM outputs
- Improves interpretability

### 5. Classification Head
- Dense layer (256 â†’ 3)
- Softmax activation
- Outputs probabilities for each class

## ğŸ“ Advanced Usage

### Extract Attention Weights

```python
# Modify test_custom_model.py to return attention weights
logits, attention_weights = model(input_ids)

# Visualize which words the model focuses on
import matplotlib.pyplot as plt
plt.imshow(attention_weights.cpu().numpy(), cmap='hot')
plt.show()
```

### Fine-tune on New Data

```python
# Load pretrained model
checkpoint = torch.load("custom_konkani_model/best_model.pt")
model.load_state_dict(checkpoint['model_state_dict'])

# Continue training with new data
trainer.train(new_train_loader, new_val_loader, num_epochs=5)
```

### Export to ONNX

```python
# For deployment
dummy_input = torch.randint(0, vocab_size, (1, 128))
torch.onnx.export(model, dummy_input, "model.onnx")
```

## ğŸš€ Deployment

### Flask API Example

```python
from flask import Flask, request, jsonify
from test_custom_model import KonkaniSentimentPredictor

app = Flask(__name__)
predictor = KonkaniSentimentPredictor()

@app.route('/predict', methods=['POST'])
def predict():
    text = request.json['text']
    result = predictor.predict(text)
    return jsonify(result)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

## ğŸ“– Next Steps

1. **Train the model**: `python train_custom_model.py`
2. **Evaluate results**: Check `test_results.json` and plots
3. **Test interactively**: `python test_custom_model.py`
4. **Experiment**: Try different hyperparameters
5. **Deploy**: Integrate into your application

## ğŸ‰ Why This is Better for You

âœ… **Fully Custom**: Built specifically for Konkani
âœ… **Lightweight**: Runs anywhere, even on mobile
âœ… **Fast**: Quick training and inference
âœ… **Transparent**: You understand every layer
âœ… **Flexible**: Easy to modify and extend
âœ… **No Black Box**: Complete control over the model

---

**Happy Training! ğŸš€**

Your custom Konkani sentiment model is ready to be trained!
