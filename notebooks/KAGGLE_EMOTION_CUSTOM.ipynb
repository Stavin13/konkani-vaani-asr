{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Konkani Emotion Detection Model - From Scratch\n",
    "\n",
    "**Approach:** Build custom LSTM/GRU model trained only on Konkani data  \n",
    "**No pre-trained models** - pure custom architecture!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nGPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch torchtext pandas scikit-learn tqdm\n",
    "print(\"âœ… Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Emotion Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "DATASET_PATH = \"/kaggle/input/konkani-emotion-data\"  # UPDATE THIS\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(f\"{DATASET_PATH}/konkani_emotion_training_data.csv\")\n",
    "\n",
    "print(f\"Dataset size: {len(df)}\")\n",
    "print(f\"\\nEmotion distribution:\")\n",
    "print(df['emotion'].value_counts())\n",
    "print(f\"\\nSample:\")\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build Custom Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Tokenize Konkani text\n",
    "def tokenize_konkani(text):\n",
    "    # Simple word tokenization for Devanagari\n",
    "    return text.strip().split()\n",
    "\n",
    "# Build vocabulary from training data\n",
    "all_tokens = []\n",
    "for text in df['text']:\n",
    "    all_tokens.extend(tokenize_konkani(text))\n",
    "\n",
    "# Count frequencies\n",
    "token_counts = Counter(all_tokens)\n",
    "\n",
    "# Build vocab (keep top 10000 words)\n",
    "vocab_size = 10000\n",
    "most_common = token_counts.most_common(vocab_size - 2)  # -2 for PAD and UNK\n",
    "\n",
    "# Create word to index mapping\n",
    "word2idx = {'<PAD>': 0, '<UNK>': 1}\n",
    "for idx, (word, _) in enumerate(most_common, start=2):\n",
    "    word2idx[word] = idx\n",
    "\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "\n",
    "print(f\"Vocabulary size: {len(word2idx)}\")\n",
    "print(f\"Total tokens: {len(all_tokens)}\")\n",
    "print(f\"Unique tokens: {len(token_counts)}\")\n",
    "print(f\"\\nMost common words:\")\n",
    "for word, count in most_common[:10]:\n",
    "    print(f\"  {word}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Encode text to indices\n",
    "def encode_text(text, word2idx, max_len=50):\n",
    "    tokens = tokenize_konkani(text)\n",
    "    indices = [word2idx.get(token, word2idx['<UNK>']) for token in tokens]\n",
    "    \n",
    "    # Pad or truncate\n",
    "    if len(indices) < max_len:\n",
    "        indices += [word2idx['<PAD>']] * (max_len - len(indices))\n",
    "    else:\n",
    "        indices = indices[:max_len]\n",
    "    \n",
    "    return indices\n",
    "\n",
    "# Create label mapping\n",
    "emotions = sorted(df['emotion'].unique())\n",
    "label2idx = {label: idx for idx, label in enumerate(emotions)}\n",
    "idx2label = {idx: label for label, idx in label2idx.items()}\n",
    "\n",
    "print(f\"Emotions: {emotions}\")\n",
    "print(f\"Label mapping: {label2idx}\")\n",
    "\n",
    "# Encode all data\n",
    "max_length = 50\n",
    "X = [encode_text(text, word2idx, max_length) for text in df['text']]\n",
    "y = [label2idx[emotion] for emotion in df['emotion']]\n",
    "\n",
    "# Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")\n",
    "\n",
    "# Dataset class\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.LongTensor(X)\n",
    "        self.y = torch.LongTensor(y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 64\n",
    "train_dataset = EmotionDataset(X_train, y_train)\n",
    "val_dataset = EmotionDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "print(f\"\\nâœ… Data prepared!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Define Custom Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class KonkaniEmotionLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes, num_layers=2, dropout=0.3):\n",
    "        super(KonkaniEmotionLSTM, self).__init__()\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # Attention layer\n",
    "        self.attention = nn.Linear(hidden_dim * 2, 1)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Embedding\n",
    "        embedded = self.embedding(x)  # (batch, seq_len, embedding_dim)\n",
    "        \n",
    "        # LSTM\n",
    "        lstm_out, _ = self.lstm(embedded)  # (batch, seq_len, hidden_dim*2)\n",
    "        \n",
    "        # Attention\n",
    "        attention_weights = torch.softmax(self.attention(lstm_out), dim=1)\n",
    "        attended = torch.sum(attention_weights * lstm_out, dim=1)  # (batch, hidden_dim*2)\n",
    "        \n",
    "        # Dropout and output\n",
    "        dropped = self.dropout(attended)\n",
    "        output = self.fc(dropped)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Model parameters\n",
    "vocab_size = len(word2idx)\n",
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "num_classes = len(emotions)\n",
    "num_layers = 2\n",
    "dropout = 0.3\n",
    "\n",
    "# Create model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = KonkaniEmotionLSTM(vocab_size, embedding_dim, hidden_dim, num_classes, num_layers, dropout)\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CUSTOM KONKANI EMOTION MODEL\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Architecture: Bidirectional LSTM with Attention\")\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "print(f\"Embedding dim: {embedding_dim}\")\n",
    "print(f\"Hidden dim: {hidden_dim}\")\n",
    "print(f\"Num classes: {num_classes}\")\n",
    "print(f\"Num layers: {num_layers}\")\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Train Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "\n",
    "# Training setup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
    "\n",
    "num_epochs = 20\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ðŸš€ TRAINING CUSTOM KONKANI EMOTION MODEL\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for batch_x, batch_y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_total += batch_y.size(0)\n",
    "        train_correct += (predicted == batch_y).sum().item()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in val_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_total += batch_y.size(0)\n",
    "            val_correct += (predicted == batch_y).sum().item()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss /= len(val_loader)\n",
    "    train_acc = 100 * train_correct / train_total\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "        }, '/kaggle/working/best_emotion_model.pt')\n",
    "        print(f\"  âœ… Best model saved!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… TRAINING COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load best model\n",
    "checkpoint = torch.load('/kaggle/working/best_emotion_model.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Get predictions\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in val_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        outputs = model(batch_x)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(batch_y.numpy())\n",
    "\n",
    "# Classification report\n",
    "print(\"=\"*70)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(all_labels, all_preds, target_names=emotions))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=emotions, yticklabels=emotions)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig('/kaggle/working/confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Confusion matrix saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Save Complete Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Create output directory\n",
    "output_dir = '/kaggle/working/konkani_emotion_custom_model'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), f'{output_dir}/model.pt')\n",
    "\n",
    "# Save vocabulary\n",
    "with open(f'{output_dir}/vocab.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(word2idx, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Save label mapping\n",
    "with open(f'{output_dir}/labels.json', 'w') as f:\n",
    "    json.dump({'label2idx': label2idx, 'idx2label': idx2label}, f, indent=2)\n",
    "\n",
    "# Save config\n",
    "config = {\n",
    "    'vocab_size': vocab_size,\n",
    "    'embedding_dim': embedding_dim,\n",
    "    'hidden_dim': hidden_dim,\n",
    "    'num_classes': num_classes,\n",
    "    'num_layers': num_layers,\n",
    "    'dropout': dropout,\n",
    "    'max_length': max_length,\n",
    "}\n",
    "with open(f'{output_dir}/config.json', 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"âœ… Model saved to:\", output_dir)\n",
    "print(\"\\nFiles:\")\n",
    "!ls -lh {output_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(text, model, word2idx, idx2label, max_length=50):\n",
    "    model.eval()\n",
    "    \n",
    "    # Encode text\n",
    "    indices = encode_text(text, word2idx, max_length)\n",
    "    x = torch.LongTensor([indices]).to(device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        output = model(x)\n",
    "        probs = torch.softmax(output, dim=1)\n",
    "        pred_idx = torch.argmax(probs, dim=1).item()\n",
    "        confidence = probs[0][pred_idx].item()\n",
    "    \n",
    "    return idx2label[pred_idx], confidence\n",
    "\n",
    "# Test samples\n",
    "test_texts = [\n",
    "    \"à¤¹à¤¾à¤‚à¤µ à¤–à¥‚à¤¶ à¤†à¤¸à¤¾\",\n",
    "    \"à¤¹à¤¾à¤‚à¤µ à¤¦à¥à¤–à¥€ à¤†à¤¸à¤¾\",\n",
    "    \"à¤¹à¤¾à¤‚à¤µ à¤°à¤¾à¤—à¥€à¤¤ à¤†à¤¸à¤¾\",\n",
    "    \"à¤¹à¤¾à¤‚à¤µ à¤­à¤¯à¤­à¥€à¤¤ à¤†à¤¸à¤¾\",\n",
    "]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TESTING CUSTOM EMOTION MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for text in test_texts:\n",
    "    emotion, confidence = predict_emotion(text, model, word2idx, idx2label, max_length)\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"Emotion: {emotion}\")\n",
    "    print(f\"Confidence: {confidence:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… CUSTOM KONKANI EMOTION MODEL READY!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
