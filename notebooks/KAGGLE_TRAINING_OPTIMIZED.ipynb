{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KonkaniVani ASR Training - Kaggle (OPTIMIZED)\n",
    "## Resume from Checkpoint 15 - Fixed Overfitting\n",
    "\n",
    "**üî• NEW: Optimized to reduce overfitting!**\n",
    "- ‚úÖ Reduced learning rate (0.0005 ‚Üí 0.0001)\n",
    "- ‚úÖ Increased dropout (0.1 ‚Üí 0.2)\n",
    "- ‚úÖ Stronger weight decay (0.000001 ‚Üí 0.0001)\n",
    "- ‚úÖ Better CTC/Attention balance (0.3 ‚Üí 0.5)\n",
    "\n",
    "**Why These Changes?**\n",
    "At Epoch 15:\n",
    "- Train Loss: 5.32\n",
    "- Val Loss: 9.59 (almost 2x! = overfitting)\n",
    "\n",
    "These settings will help the model generalize better.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Total Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Determine batch size based on GPU\n",
    "gpu_name = torch.cuda.get_device_name(0)\n",
    "if 'P100' in gpu_name:\n",
    "    print(\"\\n‚úÖ P100 detected! Using batch_size=4\")\n",
    "    BATCH_SIZE = 4\n",
    "    GRAD_ACCUM = 2\n",
    "elif 'T4' in gpu_name:\n",
    "    print(\"\\n‚úÖ T4 detected! Using batch_size=2\")\n",
    "    BATCH_SIZE = 2\n",
    "    GRAD_ACCUM = 4\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Unknown GPU: {gpu_name}. Using conservative batch_size=2\")\n",
    "    BATCH_SIZE = 2\n",
    "    GRAD_ACCUM = 4\n",
    "\n",
    "print(f\"Effective batch size: {BATCH_SIZE * GRAD_ACCUM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# UPDATE THIS PATH to your dataset\n",
    "DATASET_PATH = \"/kaggle/input/konkani-asr-complete-dataset\"\n",
    "\n",
    "print(f\"Looking for dataset at: {DATASET_PATH}\\n\")\n",
    "\n",
    "if os.path.exists(DATASET_PATH):\n",
    "    print(\"‚úÖ Dataset found!\\n\")\n",
    "    print(\"Contents:\")\n",
    "    !ls -la {DATASET_PATH}\n",
    "    \n",
    "    zip_files = list(Path(DATASET_PATH).glob('*.zip'))\n",
    "    if zip_files:\n",
    "        zip_file = zip_files[0]\n",
    "        print(f\"\\nüì¶ Extracting: {zip_file}\")\n",
    "        !unzip -q {zip_file} -d /kaggle/working/\n",
    "        print(\"‚úÖ Extracted!\")\n",
    "    else:\n",
    "        print(\"\\nüìã Copying files...\")\n",
    "        !cp -r {DATASET_PATH}/* /kaggle/working/\n",
    "        print(\"‚úÖ Copied!\")\n",
    "else:\n",
    "    print(\"‚ùå Dataset not found!\")\n",
    "    print(\"\\nAvailable datasets:\")\n",
    "    !ls -la /kaggle/input/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Navigate to Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "possible_dirs = [\n",
    "    '/kaggle/working/kaggle_package',\n",
    "    '/kaggle/working/kaggle_minimal',\n",
    "    '/kaggle/working/konkani',\n",
    "    '/kaggle/working',\n",
    "]\n",
    "\n",
    "project_dir = None\n",
    "for dir_path in possible_dirs:\n",
    "    if os.path.exists(f\"{dir_path}/training_scripts/train_konkanivani_asr.py\"):\n",
    "        project_dir = dir_path\n",
    "        break\n",
    "\n",
    "if project_dir:\n",
    "    print(f\"‚úÖ Found project at: {project_dir}\\n\")\n",
    "    os.chdir(project_dir)\n",
    "    !pwd\n",
    "else:\n",
    "    print(\"‚ùå Project not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q librosa soundfile tensorboard\n",
    "print(\"‚úÖ Dependencies ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Prepare Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p checkpoints\n",
    "!cp archives/checkpoint_epoch_15.pt checkpoints/\n",
    "print(\"‚úÖ Checkpoint ready\\n\")\n",
    "!ls -lh checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Fix Manifest Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def fix_manifest_paths(manifest_path):\n",
    "    print(f\"Fixing paths in: {manifest_path}\")\n",
    "    \n",
    "    data = []\n",
    "    with open(manifest_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                data.append(json.loads(line))\n",
    "    \n",
    "    valid_data = []\n",
    "    for item in data:\n",
    "        filename = Path(item['audio_filepath']).name\n",
    "        new_path = f\"data/konkani-asr-v0/audio/{filename}\"\n",
    "        item['audio_filepath'] = new_path\n",
    "        \n",
    "        if not filename.startswith('._') and os.path.exists(new_path):\n",
    "            valid_data.append(item)\n",
    "    \n",
    "    with open(manifest_path, 'w') as f:\n",
    "        for item in valid_data:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    print(f\"  ‚úÖ Kept {len(valid_data)} valid files\")\n",
    "    return len(valid_data)\n",
    "\n",
    "print(\"=\"*60)\n",
    "train_count = fix_manifest_paths('data/konkani-asr-v0/splits/manifests/train.json')\n",
    "val_count = fix_manifest_paths('data/konkani-asr-v0/splits/manifests/val.json')\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n‚úÖ Training samples: {train_count}\")\n",
    "print(f\"‚úÖ Validation samples: {val_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import gc\n",
    "import sys\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "os.environ['PYTHONPATH'] = os.getcwd()\n",
    "\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.insert(0, os.getcwd())\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"‚úÖ Environment ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: üöÄ START TRAINING (OPTIMIZED)\n",
    "\n",
    "### Key Changes from Original:\n",
    "- **Learning Rate**: 0.0005 ‚Üí **0.0001** (5x slower, more stable)\n",
    "- **Dropout**: 0.1 ‚Üí **0.2** (stronger regularization)\n",
    "- **Weight Decay**: 0.000001 ‚Üí **0.0001** (100x stronger)\n",
    "- **CTC Weight**: 0.3 ‚Üí **0.5** (better balance)\n",
    "\n",
    "### Expected Results:\n",
    "- Val loss should stop increasing\n",
    "- Gap between train/val loss should narrow\n",
    "- Better generalization to new audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üöÄ STARTING OPTIMIZED KONKANIVANI ASR TRAINING\")\n",
    "print(\"=\"*70)\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Gradient accumulation: {GRAD_ACCUM}x\")\n",
    "print(f\"Effective batch size: {BATCH_SIZE * GRAD_ACCUM}\")\n",
    "print(\"\\nüî• OPTIMIZED SETTINGS:\")\n",
    "print(f\"  Learning rate: 0.0001 (was 0.0005)\")\n",
    "print(f\"  Dropout: 0.2 (was 0.1)\")\n",
    "print(f\"  Weight decay: 0.0001 (was 0.000001)\")\n",
    "print(f\"  CTC weight: 0.5 (was 0.3)\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüí° TIP: Turn OFF internet now to save quota!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n\")\n",
    "\n",
    "!python3 training_scripts/train_konkanivani_asr.py \\\n",
    "    --train_manifest data/konkani-asr-v0/splits/manifests/train.json \\\n",
    "    --val_manifest data/konkani-asr-v0/splits/manifests/val.json \\\n",
    "    --vocab_file data/vocab.json \\\n",
    "    --batch_size {BATCH_SIZE} \\\n",
    "    --gradient_accumulation_steps {GRAD_ACCUM} \\\n",
    "    --num_epochs 50 \\\n",
    "    --learning_rate 0.0001 \\\n",
    "    --weight_decay 0.0001 \\\n",
    "    --dropout 0.2 \\\n",
    "    --ctc_weight 0.5 \\\n",
    "    --device cuda \\\n",
    "    --d_model 256 \\\n",
    "    --encoder_layers 12 \\\n",
    "    --decoder_layers 6 \\\n",
    "    --mixed_precision \\\n",
    "    --checkpoint_dir checkpoints \\\n",
    "    --log_dir logs \\\n",
    "    --resume checkpoints/checkpoint_epoch_15.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Monitor Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "print(\"\\nSaved checkpoints:\")\n",
    "!ls -lh checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Check Latest Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "checkpoints = sorted(Path('checkpoints').glob('checkpoint_epoch_*.pt'))\n",
    "if checkpoints:\n",
    "    latest = checkpoints[-1]\n",
    "    ckpt = torch.load(latest, map_location='cpu')\n",
    "    print(f\"Latest checkpoint: {latest.name}\")\n",
    "    print(f\"Epoch: {ckpt['epoch']}\")\n",
    "    print(f\"Train loss: {ckpt.get('train_loss', 'N/A')}\")\n",
    "    print(f\"Val loss: {ckpt.get('val_loss', 'N/A')}\")\n",
    "    \n",
    "    # Check if overfitting is improving\n",
    "    if 'train_loss' in ckpt and 'val_loss' in ckpt:\n",
    "        ratio = ckpt['val_loss'] / ckpt['train_loss']\n",
    "        print(f\"\\nVal/Train ratio: {ratio:.2f}\")\n",
    "        if ratio < 1.5:\n",
    "            print(\"‚úÖ Good! Overfitting is under control\")\n",
    "        elif ratio < 1.8:\n",
    "            print(\"‚ö†Ô∏è Moderate overfitting\")\n",
    "        else:\n",
    "            print(\"‚ùå High overfitting - may need more regularization\")\n",
    "else:\n",
    "    print(\"No checkpoints saved yet.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
