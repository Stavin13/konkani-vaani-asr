{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KonkaniVani ASR Training - Google Colab\n",
    "## Resume from Checkpoint 15 with Memory Optimization\n",
    "\n",
    "**Configuration:**\n",
    "- Model: d_model=256, 12 encoder layers, 6 decoder layers\n",
    "- Batch size: 2 (with gradient accumulation 4x)\n",
    "- Mixed precision: FP16\n",
    "- GPU: Tesla T4 (14GB)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install torch torchaudio librosa soundfile tensorboard tqdm pyyaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive (Optional - for backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set backup path\n",
    "DRIVE_BACKUP_PATH = '/content/drive/MyDrive/konkanivani_backup'\n",
    "!mkdir -p {DRIVE_BACKUP_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Copy Project from Google Drive\n",
    "\n",
    "**Your Drive folder**: https://drive.google.com/drive/folders/1-chxczmcNooqLDtsFgQ8ZT8NvzFuFARr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Navigate to content directory\n",
    "%cd /content\n",
    "\n",
    "# Option A: If you have the project as a zip file in the shared folder\n",
    "# Find the zip file in your mounted drive and extract it\n",
    "# !cp \"/content/drive/MyDrive/[YourFolder]/konkani_project.zip\" .\n",
    "# !unzip -q konkani_project.zip\n",
    "\n",
    "# Option B: Copy entire project folder from Drive\n",
    "# Replace with your actual Drive path\n",
    "DRIVE_PROJECT_PATH = \"/content/drive/MyDrive/konkani\"  # Adjust this path\n",
    "\n",
    "if Path(DRIVE_PROJECT_PATH).exists():\n",
    "    print(f\"‚úÖ Found project at: {DRIVE_PROJECT_PATH}\")\n",
    "    print(\"üìã Copying to /content/konkani...\")\n",
    "    !cp -r {DRIVE_PROJECT_PATH} /content/konkani\n",
    "    %cd /content/konkani\n",
    "    print(\"‚úÖ Project copied successfully!\")\n",
    "else:\n",
    "    print(f\"‚ùå Project not found at: {DRIVE_PROJECT_PATH}\")\n",
    "    print(\"\\nüìù Please update DRIVE_PROJECT_PATH to match your Drive structure\")\n",
    "    print(\"   Or manually copy files to /content/konkani\")\n",
    "    \n",
    "    # Create directory for manual upload\n",
    "    !mkdir -p /content/konkani\n",
    "    %cd /content/konkani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify Project Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check required files\n",
    "required_files = [\n",
    "    'training_scripts/train_konkanivani_asr.py',\n",
    "    'models/konkanivani_asr.py',\n",
    "    'data/audio_processing/dataset.py',\n",
    "    'data/audio_processing/text_tokenizer.py',\n",
    "    'data/vocab.json',\n",
    "    'data/konkani-asr-v0/splits/manifests/train.json',\n",
    "    'data/konkani-asr-v0/splits/manifests/val.json',\n",
    "    'archives/checkpoint_epoch_15.pt'\n",
    "]\n",
    "\n",
    "print(\"Checking project structure...\\n\")\n",
    "for file in required_files:\n",
    "    exists = \"‚úÖ\" if os.path.exists(file) else \"‚ùå\"\n",
    "    print(f\"{exists} {file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Copy Checkpoint to Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p checkpoints\n",
    "!cp archives/checkpoint_epoch_15.pt checkpoints/\n",
    "!ls -lh checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Verify Checkpoint Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load('checkpoints/checkpoint_epoch_15.pt', map_location='cpu')\n",
    "\n",
    "print(\"üìã Checkpoint Configuration:\")\n",
    "print(\"=\"*60)\n",
    "print(json.dumps(checkpoint.get('config', {}), indent=2))\n",
    "\n",
    "print(\"\\nüìä Model Architecture:\")\n",
    "print(\"=\"*60)\n",
    "state = checkpoint['model_state_dict']\n",
    "encoder_layers = sum(1 for k in state.keys() if 'encoder.layers.' in k and '.ff1.0.weight' in k)\n",
    "decoder_layers = sum(1 for k in state.keys() if 'decoder.decoder.layers.' in k and '.linear1.weight' in k)\n",
    "d_model = state['encoder.input_proj.weight'].shape[0]\n",
    "vocab_size = state['ctc_head.weight'].shape[0]\n",
    "\n",
    "print(f\"Encoder layers: {encoder_layers}\")\n",
    "print(f\"Decoder layers: {decoder_layers}\")\n",
    "print(f\"d_model: {d_model}\")\n",
    "print(f\"vocab_size: {vocab_size}\")\n",
    "print(f\"Epoch: {checkpoint['epoch']}\")\n",
    "print(f\"Val loss: {checkpoint.get('val_loss', 'N/A')}\")\n",
    "\n",
    "# Clear memory\n",
    "del checkpoint\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Set Memory Optimization Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variables for better memory management\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '0'\n",
    "\n",
    "print(\"‚úÖ Environment variables set:\")\n",
    "print(f\"   PYTORCH_CUDA_ALLOC_CONF={os.environ['PYTORCH_CUDA_ALLOC_CONF']}\")\n",
    "print(f\"   CUDA_LAUNCH_BLOCKING={os.environ['CUDA_LAUNCH_BLOCKING']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Clear GPU Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# Clear cache\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Check GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Total memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"Allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "    print(f\"Cached: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è CUDA not available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Start Training (Memory Optimized)\n",
    "\n",
    "### Configuration:\n",
    "- **Batch size**: 2 (reduced from 8)\n",
    "- **Gradient accumulation**: 4 steps (effective batch = 8)\n",
    "- **Mixed precision**: FP16 enabled\n",
    "- **Model**: d_model=256, 12 encoder, 6 decoder layers\n",
    "- **Resume from**: checkpoint_epoch_15.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training command\n",
    "!python3 training_scripts/train_konkanivani_asr.py \\\n",
    "    --train_manifest data/konkani-asr-v0/splits/manifests/train.json \\\n",
    "    --val_manifest data/konkani-asr-v0/splits/manifests/val.json \\\n",
    "    --vocab_file data/vocab.json \\\n",
    "    --batch_size 2 \\\n",
    "    --gradient_accumulation_steps 4 \\\n",
    "    --num_epochs 50 \\\n",
    "    --learning_rate 0.0005 \\\n",
    "    --device cuda \\\n",
    "    --d_model 256 \\\n",
    "    --encoder_layers 12 \\\n",
    "    --decoder_layers 6 \\\n",
    "    --mixed_precision \\\n",
    "    --checkpoint_dir checkpoints \\\n",
    "    --log_dir logs \\\n",
    "    --resume checkpoints/checkpoint_epoch_15.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Monitor Training (Run in Separate Cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor GPU usage\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View TensorBoard logs\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Backup to Google Drive (Run Periodically)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Backup checkpoints\n",
    "drive_backup = '/content/drive/MyDrive/konkanivani_backup'\n",
    "\n",
    "if Path(drive_backup).exists():\n",
    "    print(\"üì§ Backing up to Google Drive...\")\n",
    "    \n",
    "    # Backup checkpoints\n",
    "    !cp -r checkpoints {drive_backup}/\n",
    "    \n",
    "    # Backup logs\n",
    "    !cp -r logs {drive_backup}/\n",
    "    \n",
    "    print(\"‚úÖ Backup completed!\")\n",
    "    !ls -lh {drive_backup}/checkpoints/\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Drive not mounted or backup path doesn't exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. If Out of Memory - Reduce Batch Size Further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory first\n",
    "import torch\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Run with batch_size=1\n",
    "!python3 training_scripts/train_konkanivani_asr.py \\\n",
    "    --train_manifest data/konkani-asr-v0/splits/manifests/train.json \\\n",
    "    --val_manifest data/konkani-asr-v0/splits/manifests/val.json \\\n",
    "    --vocab_file data/vocab.json \\\n",
    "    --batch_size 1 \\\n",
    "    --gradient_accumulation_steps 8 \\\n",
    "    --num_epochs 50 \\\n",
    "    --learning_rate 0.0005 \\\n",
    "    --device cuda \\\n",
    "    --d_model 256 \\\n",
    "    --encoder_layers 12 \\\n",
    "    --decoder_layers 6 \\\n",
    "    --mixed_precision \\\n",
    "    --checkpoint_dir checkpoints \\\n",
    "    --log_dir logs \\\n",
    "    --resume checkpoints/checkpoint_epoch_15.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Download Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download best model\n",
    "if Path('checkpoints/best_model.pt').exists():\n",
    "    files.download('checkpoints/best_model.pt')\n",
    "    print(\"‚úÖ Downloaded best_model.pt\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è best_model.pt not found\")\n",
    "\n",
    "# List all checkpoints\n",
    "!ls -lh checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Test Inference (After Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "from models.konkanivani_asr import create_konkanivani_model\n",
    "from data.audio_processing.text_tokenizer import KonkaniTokenizer\n",
    "\n",
    "# Load model\n",
    "tokenizer = KonkaniTokenizer('data/vocab.json')\n",
    "model = create_konkanivani_model(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    config={\n",
    "        'input_dim': 80,\n",
    "        'd_model': 256,\n",
    "        'encoder_layers': 12,\n",
    "        'decoder_layers': 6,\n",
    "        'num_heads': 4,\n",
    "        'conv_kernel_size': 31,\n",
    "        'dropout': 0.1\n",
    "    }\n",
    ")\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load('checkpoints/best_model.pt', map_location='cuda')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully!\")\n",
    "print(f\"   Trained for {checkpoint['epoch']} epochs\")\n",
    "print(f\"   Best val loss: {checkpoint['val_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### Out of Memory Error\n",
    "1. Clear cache: `torch.cuda.empty_cache()`\n",
    "2. Reduce batch_size to 1\n",
    "3. Increase gradient_accumulation_steps to 8\n",
    "\n",
    "### Checkpoint Not Found\n",
    "1. Check if file exists: `!ls -lh archives/`\n",
    "2. Copy to checkpoints: `!cp archives/checkpoint_epoch_15.pt checkpoints/`\n",
    "\n",
    "### Training Slow\n",
    "1. Check GPU utilization: `!nvidia-smi`\n",
    "2. Ensure mixed_precision is enabled\n",
    "3. Verify GPU is being used: Check \"Device: cuda\" in training output\n",
    "\n",
    "### Session Timeout\n",
    "1. Backup to Drive regularly (every 5 epochs)\n",
    "2. Use Colab Pro for longer sessions\n",
    "3. Resume from latest checkpoint\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
