{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konkani Emotion + Translation - Dual GPU Pipeline\n",
    "\n",
    "**Strategy:** Train both models simultaneously on 2 GPUs!  \n",
    "**GPU 0:** Emotion model  \n",
    "**GPU 1:** Translation model  \n",
    "**Time:** ~2 hours (parallel training!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Check Dual GPU Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"DUAL GPU SETUP\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Available GPUs: {num_gpus}\")\n",
    "\n",
    "for i in range(num_gpus):\n",
    "    print(f\"\\nGPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "if num_gpus >= 2:\n",
    "    print(f\"\\n✅ Dual GPU detected!\")\n",
    "    print(f\"GPU 0: Emotion model training\")\n",
    "    print(f\"GPU 1: Translation model training\")\n",
    "    emotion_device = torch.device('cuda:0')\n",
    "    translation_device = torch.device('cuda:1')\n",
    "else:\n",
    "    print(f\"\\n⚠️ Single GPU - will train sequentially\")\n",
    "    emotion_device = torch.device('cuda:0')\n",
    "    translation_device = torch.device('cuda:0')\n",
    "\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers torch pandas tqdm scikit-learn sentencepiece\n",
    "print(\"✅ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Konkani Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "DATASET_PATH = \"/kaggle/input/konkani-text-data\"  # UPDATE THIS\n",
    "\n",
    "konkani_texts = []\n",
    "\n",
    "try:\n",
    "    with open(f'{DATASET_PATH}/train.json', 'r') as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "        konkani_texts = [item['text'] for item in data]\n",
    "except:\n",
    "    with open(f'{DATASET_PATH}/konkani_corpus.txt', 'r') as f:\n",
    "        konkani_texts = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "konkani_texts = list(set(konkani_texts))\n",
    "print(f\"Loaded {len(konkani_texts)} unique Konkani texts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate Data (Both Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"GENERATING TRAINING DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Emotion labels\n",
    "print(\"\\n1. Generating emotion labels...\")\n",
    "emotion_classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", device=0, top_k=None)\n",
    "\n",
    "emotion_data = []\n",
    "for i in tqdm(range(0, len(konkani_texts), 32)):\n",
    "    batch = konkani_texts[i:i+32]\n",
    "    results = emotion_classifier(batch)\n",
    "    for text, result in zip(batch, results):\n",
    "        top = max(result, key=lambda x: x['score'])\n",
    "        if top['score'] >= 0.7:\n",
    "            emotion_data.append({'text': text, 'emotion': top['label'], 'confidence': top['score']})\n",
    "\n",
    "emotion_df = pd.DataFrame(emotion_data)\n",
    "print(f\"✅ Generated {len(emotion_df)} emotion labels\")\n",
    "\n",
    "# Translation pairs\n",
    "print(\"\\n2. Generating translations...\")\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-mul-en\", device=0)\n",
    "\n",
    "translation_pairs = []\n",
    "for i in tqdm(range(0, len(konkani_texts), 16)):\n",
    "    batch = konkani_texts[i:i+16]\n",
    "    try:\n",
    "        results = translator(batch, max_length=128)\n",
    "        for konkani, result in zip(batch, results):\n",
    "            english = result['translation_text']\n",
    "            if len(english.split()) >= 2 and english != konkani:\n",
    "                translation_pairs.append({'konkani': konkani, 'english': english})\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f\"✅ Generated {len(translation_pairs)} translation pairs\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "isGpuEnabled": true,
   "isInternetEnabled": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
