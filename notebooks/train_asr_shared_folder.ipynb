{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéôÔ∏è KonkaniVani ASR Training - Shared Folder Setup\n",
    "\n",
    "**Training from shared folder link**\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Before You Start:\n",
    "\n",
    "1. **Add shared folder to your Drive**:\n",
    "   - Open: https://drive.google.com/drive/folders/1KX7k_z2negFKq3qFjHJh-K1U-MEcNp7P\n",
    "   - Click \"Add shortcut to Drive\" (‚≠ê icon)\n",
    "   - Choose \"My Drive\"\n",
    "\n",
    "2. **Enable GPU in Colab**:\n",
    "   - Runtime ‚Üí Change runtime type ‚Üí GPU (T4) ‚Üí Save\n",
    "\n",
    "3. **Run cells in order** (1 ‚Üí 8)\n",
    "\n",
    "---\n",
    "\n",
    "**Estimated time**: 10 min setup + 12 hours training\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Cell 1: Install Dependencies\n",
    "\n",
    "**Time**: ~2 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì¶ Installing dependencies...\")\n",
    "!pip install -q torch torchaudio tensorboard jiwer pyyaml soundfile\n",
    "print(\"‚úÖ Dependencies installed!\\n\")\n",
    "\n",
    "# Check GPU\n",
    "print(\"üîç GPU Check:\")\n",
    "!nvidia-smi --query-gpu=name,memory.total --format=csv,noheader\n",
    "print(\"\\n‚úÖ If you see 'Tesla T4, 15360 MiB' above, you're ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Cell 2: Mount Drive & Find Shared Folder\n",
    "\n",
    "**Time**: ~1 minute\n",
    "\n",
    "**Important**: Make sure you added the shared folder shortcut to \"My Drive\" before running this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Mount Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîç ACCESSING SHARED FOLDER\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "print(\"Searching for shared files...\\n\")\n",
    "\n",
    "# Search for the files\n",
    "result = subprocess.run(\n",
    "    [\"find\", \"/content/drive\", \"-name\", \"checkpoint_epoch_15.pt\", \"-o\", \"-name\", \"konkani_project.zip\"],\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    "    timeout=30\n",
    ")\n",
    "\n",
    "found_files = [f for f in result.stdout.strip().split('\\n') if f]\n",
    "\n",
    "if found_files:\n",
    "    print(\"‚úÖ Found files:\\n\")\n",
    "    for f in found_files:\n",
    "        print(f\"   {f}\")\n",
    "    \n",
    "    # Get the folder path\n",
    "    folder_path = os.path.dirname(found_files[0])\n",
    "    print(f\"\\n‚úÖ Folder location: {folder_path}\\n\")\n",
    "    \n",
    "    # Verify all 3 files\n",
    "    files_to_check = ['checkpoint_epoch_15.pt', 'konkani_project.zip', 'vocab.json']\n",
    "    print(\"üìã Verifying files:\\n\")\n",
    "    \n",
    "    all_found = True\n",
    "    for filename in files_to_check:\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        if os.path.exists(filepath):\n",
    "            size_mb = os.path.getsize(filepath) / (1024*1024)\n",
    "            print(f\"‚úÖ {filename} ({size_mb:.1f} MB)\")\n",
    "        else:\n",
    "            print(f\"‚ùå {filename} - NOT FOUND\")\n",
    "            all_found = False\n",
    "    \n",
    "    if all_found:\n",
    "        # Save the folder path for next cells\n",
    "        with open('/tmp/folder_path.txt', 'w') as f:\n",
    "            f.write(folder_path)\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"‚úÖ ALL FILES FOUND! Ready to proceed.\")\n",
    "        print(\"=\"*70)\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  Some files missing!\")\n",
    "else:\n",
    "    print(\"‚ùå Could not find files!\")\n",
    "    print(\"\\nüîß Troubleshooting:\")\n",
    "    print(\"1. Did you add the shared folder shortcut to 'My Drive'?\")\n",
    "    print(\"2. Open this link and click 'Add shortcut to Drive':\")\n",
    "    print(\"   https://drive.google.com/drive/folders/1KX7k_z2negFKq3qFjHJh-K1U-MEcNp7P\")\n",
    "    print(\"3. Refresh this page and try again\")\n",
    "    print(\"\\nSearching all of Drive (this may take a moment)...\")\n",
    "    !find /content/drive -name \"*.pt\" -o -name \"konkani_project.zip\" 2>/dev/null | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Cell 3: Extract Project\n",
    "\n",
    "**Time**: ~3 minutes\n",
    "\n",
    "This extracts the 14GB project zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check if Cell 2 found the files\n",
    "if not os.path.exists('/tmp/folder_path.txt'):\n",
    "    print(\"‚ùå ERROR: Cell 2 didn't find the files!\\n\")\n",
    "    print(\"üîß Please do this:\")\n",
    "    print(\"1. Open: https://drive.google.com/drive/folders/1KX7k_z2negFKq3qFjHJh-K1U-MEcNp7P\")\n",
    "    print(\"2. Click 'Add shortcut to Drive' (‚≠ê icon at top)\")\n",
    "    print(\"3. Choose 'My Drive'\")\n",
    "    print(\"4. Go back and re-run Cell 2\")\n",
    "    print(\"5. Then come back and run this cell\\n\")\n",
    "    print(\"‚ö†Ô∏è  STOP HERE - Don't run more cells until Cell 2 succeeds!\")\n",
    "    raise SystemExit(\"Please fix Cell 2 first\")\n",
    "\n",
    "# Get folder path from previous cell\n",
    "with open('/tmp/folder_path.txt', 'r') as f:\n",
    "    folder_path = f.read().strip()\n",
    "\n",
    "print(f\"üìÇ Using files from: {folder_path}\\n\")\n",
    "print(\"üì¶ Extracting konkani_project.zip...\")\n",
    "print(\"   This takes 2-3 minutes...\\n\")\n",
    "\n",
    "# Extract\n",
    "zip_path = os.path.join(folder_path, 'konkani_project.zip')\n",
    "!unzip -q {zip_path} -d /content/\n",
    "\n",
    "print(\"‚úÖ Extraction complete!\\n\")\n",
    "\n",
    "# Find project location\n",
    "print(\"üîç Locating project files...\\n\")\n",
    "\n",
    "possible_paths = [\n",
    "    '/content/konkani',\n",
    "    '/content/konkani_project',\n",
    "    '/content'\n",
    "]\n",
    "\n",
    "project_path = None\n",
    "for path in possible_paths:\n",
    "    if os.path.exists(f\"{path}/training_scripts/train_konkanivani_asr.py\"):\n",
    "        project_path = path\n",
    "        break\n",
    "\n",
    "if project_path:\n",
    "    print(f\"‚úÖ Project found at: {project_path}\")\n",
    "    os.chdir(project_path)\n",
    "    print(f\"‚úÖ Working directory: {os.getcwd()}\\n\")\n",
    "    \n",
    "    # Verify key files\n",
    "    print(\"üìã Verifying extracted files:\\n\")\n",
    "    key_files = [\n",
    "        'training_scripts/train_konkanivani_asr.py',\n",
    "        'models/konkanivani_asr.py',\n",
    "        'data/audio_processing/dataset.py',\n",
    "        'data/konkani-asr-v0/splits/manifests/train.json'\n",
    "    ]\n",
    "    \n",
    "    for f in key_files:\n",
    "        status = \"‚úÖ\" if os.path.exists(f) else \"‚ùå\"\n",
    "        print(f\"{status} {f}\")\n",
    "    \n",
    "    # Save project path for next cells\n",
    "    with open('/tmp/project_path.txt', 'w') as f:\n",
    "        f.write(project_path)\n",
    "    \n",
    "    print(\"\\n‚úÖ Ready for next step!\")\n",
    "else:\n",
    "    print(\"‚ùå Could not find project!\")\n",
    "    print(\"\\nSearching...\")\n",
    "    !find /content -name \"train_konkanivani_asr.py\" -type f 2>/dev/null\n",
    "    print(\"\\nüí° Tip: The training script should be in training_scripts/ folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Cell 4: Copy Checkpoint & Vocab\n",
    "\n",
    "**Time**: ~30 seconds\n",
    "\n",
    "Copies the checkpoint and vocabulary files to the project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Get paths from previous cells\n",
    "with open('/tmp/folder_path.txt', 'r') as f:\n",
    "    folder_path = f.read().strip()\n",
    "\n",
    "with open('/tmp/project_path.txt', 'r') as f:\n",
    "    project_path = f.read().strip()\n",
    "\n",
    "os.chdir(project_path)\n",
    "\n",
    "print(\"üìã Setting up checkpoint and vocab...\\n\")\n",
    "\n",
    "# Create checkpoints directory\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "\n",
    "# Copy checkpoint\n",
    "checkpoint_src = os.path.join(folder_path, 'checkpoint_epoch_15.pt')\n",
    "checkpoint_dst = 'checkpoints/checkpoint_epoch_15.pt'\n",
    "\n",
    "if os.path.exists(checkpoint_src):\n",
    "    print(f\"üì• Copying checkpoint...\")\n",
    "    shutil.copy(checkpoint_src, checkpoint_dst)\n",
    "    size_mb = os.path.getsize(checkpoint_dst) / (1024*1024)\n",
    "    print(f\"‚úÖ Checkpoint ready ({size_mb:.1f} MB)\")\n",
    "else:\n",
    "    print(f\"‚ùå Checkpoint not found!\")\n",
    "\n",
    "# Copy vocab if needed\n",
    "vocab_src = os.path.join(folder_path, 'vocab.json')\n",
    "if not os.path.exists('vocab.json') and os.path.exists(vocab_src):\n",
    "    shutil.copy(vocab_src, 'vocab.json')\n",
    "    print(f\"‚úÖ Copied vocab.json\")\n",
    "elif os.path.exists('vocab.json'):\n",
    "    print(f\"‚úÖ vocab.json already present\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  vocab.json not found\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ SETUP COMPLETE! Ready to train.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Cell 5: Start Training!\n",
    "\n",
    "**Time**: ~12 hours\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANT**: Keep this browser tab open during training!\n",
    "\n",
    "This will:\n",
    "- Resume from Epoch 15\n",
    "- Train until Epoch 50 (35 epochs remaining)\n",
    "- Save checkpoints every 5 epochs\n",
    "- Save best model when validation improves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üöÄ STARTING KONKANIVANI ASR TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Verify checkpoint\n",
    "checkpoint_path = \"checkpoints/checkpoint_epoch_15.pt\"\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(\"\\n‚úÖ Resuming from checkpoint_epoch_15.pt\")\n",
    "    print(\"   Training: Epoch 16 ‚Üí 50 (35 epochs)\")\n",
    "    print(\"   Estimated time: ~12 hours\")\n",
    "    print(\"   Using Account B's Colab quota\\n\")\n",
    "    resume_flag = f\"--resume {checkpoint_path}\"\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Starting from scratch\")\n",
    "    print(\"   Training: Epoch 1 ‚Üí 50\")\n",
    "    print(\"   Estimated time: ~20 hours\\n\")\n",
    "    resume_flag = \"\"\n",
    "\n",
    "print(\"üìä Configuration:\")\n",
    "print(\"   ‚Ä¢ GPU: Tesla T4\")\n",
    "print(\"   ‚Ä¢ Batch size: 2 (gradient accumulation: 4x = effective batch 8)\")\n",
    "print(\"   ‚Ä¢ Mixed precision: FP16 (saves GPU memory)\")\n",
    "print(\"   ‚Ä¢ Model: d_model=256, 12 encoder, 6 decoder layers\")\n",
    "print(\"   ‚Ä¢ Checkpoints: Every 5 epochs\")\n",
    "print(\"   ‚Ä¢ Data: From shared folder\\n\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING STARTED - KEEP THIS TAB OPEN!\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Start training\n",
    "!python3 training_scripts/train_konkanivani_asr.py \\\n",
    "    --train_manifest data/konkani-asr-v0/splits/manifests/train.json \\\n",
    "    --val_manifest data/konkani-asr-v0/splits/manifests/val.json \\\n",
    "    --vocab_file data/vocab.json \\\n",
    "    --batch_size 2 \\\n",
    "    --gradient_accumulation_steps 4 \\\n",
    "    --num_epochs 50 \\\n",
    "    --learning_rate 0.0005 \\\n",
    "    --device cuda \\\n",
    "    --d_model 256 \\\n",
    "    --encoder_layers 12 \\\n",
    "    --decoder_layers 6 \\\n",
    "    --mixed_precision \\\n",
    "    --checkpoint_dir checkpoints \\\n",
    "    --log_dir logs \\\n",
    "    {resume_flag}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Cell 6: Monitor Progress\n",
    "\n",
    "**Run this anytime** to check training status.\n",
    "\n",
    "Shows:\n",
    "- Saved checkpoints\n",
    "- GPU usage\n",
    "- Recent training logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "print(f\"üìä Training Status - {datetime.now().strftime('%H:%M:%S')}\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Checkpoints\n",
    "print(\"\\nüíæ Saved Checkpoints:\\n\")\n",
    "!ls -lth checkpoints/ 2>/dev/null | head -8 || echo \"No checkpoints yet\"\n",
    "\n",
    "# GPU\n",
    "print(\"\\nüî• GPU Usage:\\n\")\n",
    "!nvidia-smi --query-gpu=utilization.gpu,memory.used,temperature.gpu --format=csv,noheader\n",
    "\n",
    "# Logs\n",
    "print(\"\\nüìù Recent Training Log:\\n\")\n",
    "!tail -25 logs/training.log 2>/dev/null || echo \"Log not created yet\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Cell 7: Backup to Drive\n",
    "\n",
    "**Run this every 2-3 hours** to save your progress!\n",
    "\n",
    "Backs up:\n",
    "- All checkpoints\n",
    "- Training logs\n",
    "\n",
    "Saved to: `MyDrive/konkanivani_backups/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "backup_path = f\"/content/drive/MyDrive/konkanivani_backups/backup_{timestamp}\"\n",
    "\n",
    "print(f\"üíæ Backing up to your Drive...\\n\")\n",
    "print(f\"Location: {backup_path}\\n\")\n",
    "\n",
    "!mkdir -p {backup_path}\n",
    "!cp -r checkpoints/* {backup_path}/ 2>/dev/null\n",
    "!cp -r logs {backup_path}/ 2>/dev/null\n",
    "\n",
    "print(\"‚úÖ Backup complete!\\n\")\n",
    "print(\"üìã Backed up files:\\n\")\n",
    "!ls -lh {backup_path}/\n",
    "\n",
    "print(\"\\nüí° Tip: Run this cell every 2-3 hours to save progress!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Cell 8: Download Final Model\n",
    "\n",
    "**Run this after training completes!**\n",
    "\n",
    "This will:\n",
    "1. Package the best model with all needed files\n",
    "2. Save to your Drive\n",
    "3. Download to your computer\n",
    "\n",
    "You'll get a zip file with:\n",
    "- `best_model.pt` - Your trained model\n",
    "- `vocab.json` - Vocabulary\n",
    "- `models/` - Model architecture code\n",
    "- `inference_konkanivani.py` - Script to use the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "print(\"üì¶ Packaging final model...\\n\")\n",
    "\n",
    "# Create package\n",
    "!mkdir -p final_model\n",
    "\n",
    "# Copy best model (or latest if best doesn't exist)\n",
    "if os.path.exists('checkpoints/best_model.pt'):\n",
    "    !cp checkpoints/best_model.pt final_model/\n",
    "    print(\"‚úÖ Using best_model.pt\")\n",
    "else:\n",
    "    !cp checkpoints/checkpoint_epoch_50.pt final_model/best_model.pt 2>/dev/null\n",
    "    print(\"‚úÖ Using checkpoint_epoch_50.pt as best_model.pt\")\n",
    "\n",
    "# Copy supporting files\n",
    "!cp vocab.json final_model/\n",
    "!cp -r models final_model/\n",
    "!cp inference_konkanivani.py final_model/ 2>/dev/null\n",
    "\n",
    "print(\"‚úÖ Copied supporting files\\n\")\n",
    "\n",
    "# Create zip\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "zip_name = f\"konkanivani_final_{timestamp}.zip\"\n",
    "!zip -r {zip_name} final_model/\n",
    "\n",
    "print(f\"\\n‚úÖ Created: {zip_name}\")\n",
    "!ls -lh {zip_name}\n",
    "\n",
    "# Save to Drive\n",
    "!mkdir -p /content/drive/MyDrive/konkanivani_final_models\n",
    "!cp {zip_name} /content/drive/MyDrive/konkanivani_final_models/\n",
    "\n",
    "print(f\"\\n‚úÖ Saved to Drive!\")\n",
    "print(f\"   Location: MyDrive/konkanivani_final_models/{zip_name}\")\n",
    "\n",
    "# Download\n",
    "print(f\"\\nüì• Downloading to your computer...\")\n",
    "files.download(zip_name)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ TRAINING COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nYour model is ready to use!\")\n",
    "print(\"Extract the zip and use inference_konkanivani.py to test it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîß Troubleshooting\n",
    "\n",
    "### Cell 2: \"Files not found\"\n",
    "**Solution**: Make sure you added the shared folder shortcut to \"My Drive\"\n",
    "1. Open: https://drive.google.com/drive/folders/1KX7k_z2negFKq3qFjHJh-K1U-MEcNp7P\n",
    "2. Click \"Add shortcut to Drive\" (‚≠ê icon at top)\n",
    "3. Choose \"My Drive\"\n",
    "4. Re-run Cell 2\n",
    "\n",
    "### Cell 5: \"Out of memory\"\n",
    "**Solution**: Reduce batch size\n",
    "- Change `--batch_size 16` to `--batch_size 8`\n",
    "- Or `--batch_size 4` if still failing\n",
    "\n",
    "### Training stopped / Runtime disconnected\n",
    "**Solution**: Just reconnect and resume\n",
    "1. Reconnect to runtime\n",
    "2. Re-run Cells 1-4 (quick setup)\n",
    "3. Re-run Cell 5 (will resume from last checkpoint)\n",
    "\n",
    "### \"Account B also hit limit\"\n",
    "**Solution**: Wait or try alternatives\n",
    "- Wait 24 hours for quota reset\n",
    "- Try Kaggle (free GPU): https://kaggle.com\n",
    "- Consider Colab Pro ($10/month)\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Tips\n",
    "\n",
    "1. **Keep tab open**: Colab disconnects after 90 min of inactivity\n",
    "2. **Backup regularly**: Run Cell 7 every 2-3 hours\n",
    "3. **Monitor progress**: Run Cell 6 to check status\n",
    "4. **GPU usage**: Should be 90-100% during training\n",
    "5. **Checkpoints**: Automatically saved every 5 epochs\n",
    "\n",
    "---\n",
    "\n",
    "## ‚è∞ Timeline\n",
    "\n",
    "| Step | Time |\n",
    "|------|------|\n",
    "| Cell 1: Dependencies | 2 min |\n",
    "| Cell 2: Mount Drive | 1 min |\n",
    "| Cell 3: Extract | 3 min |\n",
    "| Cell 4: Copy files | 30 sec |\n",
    "| Cell 5: Training | ~12 hours |\n",
    "| **Total** | **~12 hours** |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Success Checklist\n",
    "\n",
    "Before starting Cell 5:\n",
    "- [ ] Cell 1: GPU shows \"Tesla T4\"\n",
    "- [ ] Cell 2: All 3 files found (‚úÖ marks)\n",
    "- [ ] Cell 3: Project extracted successfully\n",
    "- [ ] Cell 4: Checkpoint copied (293.9 MB)\n",
    "- [ ] Ready to train!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
