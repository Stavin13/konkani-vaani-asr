{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Emotion Labels for Konkani Text\n",
    "\n",
    "**Strategy:** Use pre-trained multilingual emotion model to label Konkani text  \n",
    "**Then:** Train custom Konkani-specific emotion model on this data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers torch pandas tqdm\n",
    "print(\"✅ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Pre-trained Emotion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# Use multilingual emotion classifier\n",
    "emotion_classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "    device=0 if torch.cuda.is_available() else -1,\n",
    "    top_k=None\n",
    ")\n",
    "\n",
    "print(\"✅ Pre-trained emotion model loaded!\")\n",
    "print(f\"Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Your Konkani Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load your Konkani text (from ASR transcripts, NER data, or other sources)\n",
    "# Option 1: From ASR transcripts\n",
    "with open('data/konkani-asr-v0/splits/manifests/train.json', 'r') as f:\n",
    "    asr_data = [json.loads(line) for line in f]\n",
    "    konkani_texts = [item['text'] for item in asr_data]\n",
    "\n",
    "# Option 2: From generated data\n",
    "# df = pd.read_json('data/generated/konkani_large_dataset.json')\n",
    "# konkani_texts = df['text'].tolist()\n",
    "\n",
    "# Option 3: From custom corpus\n",
    "# with open('your_konkani_corpus.txt', 'r') as f:\n",
    "#     konkani_texts = f.readlines()\n",
    "\n",
    "print(f\"Loaded {len(konkani_texts)} Konkani texts\")\n",
    "print(f\"\\nSamples:\")\n",
    "for i in range(min(3, len(konkani_texts))):\n",
    "    print(f\"  {i+1}. {konkani_texts[i][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate Emotion Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Generate labels in batches\n",
    "batch_size = 32\n",
    "labeled_data = []\n",
    "\n",
    "print(\"Generating emotion labels...\\n\")\n",
    "\n",
    "for i in tqdm(range(0, len(konkani_texts), batch_size)):\n",
    "    batch = konkani_texts[i:i+batch_size]\n",
    "    \n",
    "    # Get predictions\n",
    "    results = emotion_classifier(batch)\n",
    "    \n",
    "    # Store with highest confidence emotion\n",
    "    for text, result in zip(batch, results):\n",
    "        # Get top emotion\n",
    "        top_emotion = max(result, key=lambda x: x['score'])\n",
    "        \n",
    "        labeled_data.append({\n",
    "            'text': text,\n",
    "            'emotion': top_emotion['label'],\n",
    "            'confidence': top_emotion['score'],\n",
    "            'all_scores': {r['label']: r['score'] for r in result}\n",
    "        })\n",
    "\n",
    "print(f\"\\n✅ Generated {len(labeled_data)} labeled samples!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Filter High-Confidence Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only high-confidence predictions for training\n",
    "confidence_threshold = 0.7\n",
    "\n",
    "high_conf_data = [d for d in labeled_data if d['confidence'] >= confidence_threshold]\n",
    "\n",
    "print(f\"Total samples: {len(labeled_data)}\")\n",
    "print(f\"High confidence (≥{confidence_threshold}): {len(high_conf_data)}\")\n",
    "print(f\"Filtered out: {len(labeled_data) - len(high_conf_data)}\")\n",
    "\n",
    "# Show distribution\n",
    "df = pd.DataFrame(high_conf_data)\n",
    "print(f\"\\nEmotion distribution:\")\n",
    "print(df['emotion'].value_counts())\n",
    "\n",
    "print(f\"\\nAverage confidence: {df['confidence'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Balance Dataset (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance classes by undersampling majority or oversampling minority\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Find minimum class size\n",
    "min_samples = df['emotion'].value_counts().min()\n",
    "target_samples = min(min_samples * 2, 500)  # At least 500 per class\n",
    "\n",
    "balanced_dfs = []\n",
    "for emotion in df['emotion'].unique():\n",
    "    emotion_df = df[df['emotion'] == emotion]\n",
    "    \n",
    "    if len(emotion_df) > target_samples:\n",
    "        # Undersample\n",
    "        emotion_df = resample(emotion_df, n_samples=target_samples, random_state=42)\n",
    "    elif len(emotion_df) < target_samples:\n",
    "        # Oversample\n",
    "        emotion_df = resample(emotion_df, n_samples=target_samples, random_state=42, replace=True)\n",
    "    \n",
    "    balanced_dfs.append(emotion_df)\n",
    "\n",
    "balanced_df = pd.concat(balanced_dfs).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Balanced dataset size: {len(balanced_df)}\")\n",
    "print(f\"\\nBalanced distribution:\")\n",
    "print(balanced_df['emotion'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Save Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('data/generated', exist_ok=True)\n",
    "\n",
    "# Save as CSV for training\n",
    "balanced_df[['text', 'emotion', 'confidence']].to_csv(\n",
    "    'data/generated/konkani_emotion_training_data.csv',\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# Save full data with all scores as JSON\n",
    "with open('data/generated/konkani_emotion_full_data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(labeled_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ Saved training data:\")\n",
    "print(\"   - data/generated/konkani_emotion_training_data.csv\")\n",
    "print(\"   - data/generated/konkani_emotion_full_data.json\")\n",
    "\n",
    "print(f\"\\nReady for training with {len(balanced_df)} samples!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Verify Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show samples from each emotion\n",
    "print(\"=\"*70)\n",
    "print(\"SAMPLE LABELED DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for emotion in balanced_df['emotion'].unique():\n",
    "    print(f\"\\n{emotion.upper()}:\")\n",
    "    samples = balanced_df[balanced_df['emotion'] == emotion].head(3)\n",
    "    for idx, row in samples.iterrows():\n",
    "        print(f\"  • {row['text'][:80]}... (conf: {row['confidence']:.3f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✅ DATA GENERATION COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nNext step: Upload this data to Kaggle and train custom model!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
