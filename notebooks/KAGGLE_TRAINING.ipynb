{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KonkaniVani ASR Training - Kaggle\n",
    "## Resume from Checkpoint 15 - Optimized for P100/T4\n",
    "\n",
    "**Why Kaggle?**\n",
    "- ‚úÖ 30 hours GPU per week (vs Colab's 12h max)\n",
    "- ‚úÖ P100 GPU with 16GB memory (more than T4's 15GB)\n",
    "- ‚úÖ Auto-saves outputs (checkpoints persist)\n",
    "- ‚úÖ Can restart and continue training\n",
    "- ‚úÖ Better for long training runs\n",
    "\n",
    "**Configuration:**\n",
    "- Model: d_model=256, 12 encoder, 6 decoder layers\n",
    "- Batch size: 4 on P100 (16GB) or 2 on T4 (15GB)\n",
    "- Gradient accumulation: 2x or 4x\n",
    "- Mixed precision: FP16\n",
    "- Resume from: Epoch 15\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Instructions\n",
    "\n",
    "### Before Running:\n",
    "\n",
    "1. **Upload Dataset**:\n",
    "   - Go to Kaggle ‚Üí Datasets ‚Üí New Dataset\n",
    "   - Upload your `konkani_project.zip`\n",
    "   - Make it private\n",
    "   - Note the dataset name (e.g., `yourusername/konkani-asr`)\n",
    "\n",
    "2. **Create Notebook**:\n",
    "   - New Notebook\n",
    "   - Settings ‚Üí Accelerator ‚Üí GPU P100 (or T4)\n",
    "   - Settings ‚Üí Internet ‚Üí ON (for setup only)\n",
    "   - Add your dataset to notebook\n",
    "\n",
    "3. **Update Cell 2**:\n",
    "   - Change `DATASET_PATH` to your dataset location\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Total Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Determine batch size based on GPU\n",
    "gpu_name = torch.cuda.get_device_name(0)\n",
    "if 'P100' in gpu_name:\n",
    "    print(\"\\n‚úÖ P100 detected! Using batch_size=4\")\n",
    "    BATCH_SIZE = 4\n",
    "    GRAD_ACCUM = 2\n",
    "elif 'T4' in gpu_name:\n",
    "    print(\"\\n‚úÖ T4 detected! Using batch_size=2\")\n",
    "    BATCH_SIZE = 2\n",
    "    GRAD_ACCUM = 4\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Unknown GPU: {gpu_name}. Using conservative batch_size=2\")\n",
    "    BATCH_SIZE = 2\n",
    "    GRAD_ACCUM = 4\n",
    "\n",
    "print(f\"Effective batch size: {BATCH_SIZE * GRAD_ACCUM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================\n",
    "# UPDATE THIS PATH\n",
    "# ============================================\n",
    "# After adding your dataset to the notebook, it will be in:\n",
    "# /kaggle/input/[your-dataset-name]/\n",
    "\n",
    "DATASET_PATH = \"/kaggle/input/konkani-asr-complete-dataset\"\n",
    "\n",
    "# ============================================\n",
    "\n",
    "print(f\"Looking for dataset at: {DATASET_PATH}\\n\")\n",
    "\n",
    "if os.path.exists(DATASET_PATH):\n",
    "    print(\"‚úÖ Dataset found!\\n\")\n",
    "    print(\"Contents:\")\n",
    "    !ls -la {DATASET_PATH}\n",
    "    \n",
    "    # Find zip file\n",
    "    zip_files = list(Path(DATASET_PATH).glob('*.zip'))\n",
    "    if zip_files:\n",
    "        zip_file = zip_files[0]\n",
    "        print(f\"\\nüì¶ Extracting: {zip_file}\")\n",
    "        !unzip -q {zip_file} -d /kaggle/working/\n",
    "        print(\"‚úÖ Extracted!\")\n",
    "    else:\n",
    "        print(\"\\nüìã Copying files...\")\n",
    "        !cp -r {DATASET_PATH}/* /kaggle/working/\n",
    "        print(\"‚úÖ Copied!\")\n",
    "else:\n",
    "    print(\"‚ùå Dataset not found!\")\n",
    "    print(\"\\nAvailable datasets:\")\n",
    "    !ls -la /kaggle/input/\n",
    "    print(\"\\nüìù Please:\")\n",
    "    print(\"   1. Add your dataset to this notebook (click Add Data)\")\n",
    "    print(\"   2. Search for: stavin12/stavinkonkani-asr\")\n",
    "    print(\"   3. Update DATASET_PATH above if needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Navigate to Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Find project directory\n",
    "possible_dirs = [\n",
    "    '/kaggle/working/kaggle_package',\n",
    "    '/kaggle/working/kaggle_minimal',\n",
    "    '/kaggle/working/konkani',\n",
    "    '/kaggle/working/konkani_project',\n",
    "    '/kaggle/working',\n",
    "]\n",
    "\n",
    "project_dir = None\n",
    "for dir_path in possible_dirs:\n",
    "    if os.path.exists(f\"{dir_path}/training_scripts/train_konkanivani_asr.py\"):\n",
    "        project_dir = dir_path\n",
    "        break\n",
    "\n",
    "if project_dir:\n",
    "    print(f\"‚úÖ Found project at: {project_dir}\\n\")\n",
    "    os.chdir(project_dir)\n",
    "    !pwd\n",
    "    print(\"\\nContents:\")\n",
    "    !ls -la\n",
    "else:\n",
    "    print(\"‚ùå Project not found. Checking /kaggle/working:\")\n",
    "    !ls -la /kaggle/working/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle has most packages pre-installed, but let's ensure we have everything\n",
    "!pip install -q librosa soundfile tensorboard\n",
    "print(\"‚úÖ Dependencies ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Verify Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "required_files = [\n",
    "    'training_scripts/train_konkanivani_asr.py',\n",
    "    'models/konkanivani_asr.py',\n",
    "    'data/audio_processing/dataset.py',\n",
    "    'data/audio_processing/text_tokenizer.py',\n",
    "    'data/vocab.json',\n",
    "    'data/konkani-asr-v0/splits/manifests/train.json',\n",
    "    'data/konkani-asr-v0/splits/manifests/val.json',\n",
    "    'archives/checkpoint_epoch_15.pt'\n",
    "]\n",
    "\n",
    "print(\"Checking required files...\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_good = True\n",
    "for file in required_files:\n",
    "    exists = os.path.exists(file)\n",
    "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "    print(f\"{status} {file}\")\n",
    "    if not exists:\n",
    "        all_good = False\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "if all_good:\n",
    "    print(\"\\nüéâ All files found! Ready to train!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Some files are missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Prepare Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p checkpoints\n",
    "!cp archives/checkpoint_epoch_15.pt checkpoints/\n",
    "\n",
    "print(\"‚úÖ Checkpoint ready\\n\")\n",
    "!ls -lh checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Verify Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "\n",
    "checkpoint = torch.load('checkpoints/checkpoint_epoch_15.pt', map_location='cpu')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CHECKPOINT CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(json.dumps(checkpoint.get('config', {}), indent=2))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL ARCHITECTURE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "state = checkpoint['model_state_dict']\n",
    "encoder_layers = sum(1 for k in state.keys() if 'encoder.layers.' in k and '.ff1.0.weight' in k)\n",
    "decoder_layers = sum(1 for k in state.keys() if 'decoder.decoder.layers.' in k and '.linear1.weight' in k)\n",
    "d_model = state['encoder.input_proj.weight'].shape[0]\n",
    "vocab_size = state['ctc_head.weight'].shape[0]\n",
    "\n",
    "print(f\"Encoder layers:  {encoder_layers}\")\n",
    "print(f\"Decoder layers:  {decoder_layers}\")\n",
    "print(f\"d_model:         {d_model}\")\n",
    "print(f\"vocab_size:      {vocab_size}\")\n",
    "print(f\"Last epoch:      {checkpoint['epoch']}\")\n",
    "print(f\"Val loss:        {checkpoint.get('val_loss', 'N/A')}\")\n",
    "\n",
    "del checkpoint\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n‚úÖ Checkpoint verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Environment variables\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '0'\n",
    "\n",
    "# Clear memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"GPU STATUS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"GPU:             {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Total memory:    {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "print(f\"Allocated:       {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "print(f\"Cached:          {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
    "print(\"\\n‚úÖ Ready to train!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Check Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Check if audio files exist\n",
    "audio_dir = Path('data/konkani-asr-v0/data/processed_segments_diarized/audio_segments')\n",
    "\n",
    "if audio_dir.exists():\n",
    "    audio_files = list(audio_dir.glob('*.wav'))\n",
    "    print(f\"‚úÖ Found {len(audio_files)} audio files\")\n",
    "    if audio_files:\n",
    "        print(f\"   First file: {audio_files[0].name}\")\n",
    "        print(f\"   Last file: {audio_files[-1].name}\")\n",
    "else:\n",
    "    print(f\"‚ùå Audio directory not found: {audio_dir}\")\n",
    "    print(\"\\nLooking for audio files...\")\n",
    "    !find data -name '*.wav' -type f | head -20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Fix Manifest Paths\n",
    "\n",
    "The manifest files contain absolute paths from your local machine. We need to update them to Kaggle paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def fix_manifest_paths(manifest_path):\n",
    "    \"\"\"Update absolute paths in manifest to relative paths\"\"\"\n",
    "    print(f\"Fixing paths in: {manifest_path}\")\n",
    "    \n",
    "    # Read JSONL format (one JSON object per line)\n",
    "    data = []\n",
    "    with open(manifest_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                data.append(json.loads(line))\n",
    "    \n",
    "    fixed_count = 0\n",
    "    missing_count = 0\n",
    "    valid_data = []\n",
    "    \n",
    "    for item in data:\n",
    "        old_path = item['audio_filepath']\n",
    "        \n",
    "        # Extract just the filename (e.g., segment_000001.wav)\n",
    "        filename = Path(old_path).name\n",
    "        \n",
    "        # New path: data/konkani-asr-v0/audio/segment_XXXXX.wav\n",
    "        new_path = f\"data/konkani-asr-v0/audio/{filename}\"\n",
    "        item['audio_filepath'] = new_path\n",
    "        fixed_count += 1\n",
    "        \n",
    "        # Check if file exists (skip ._ files which are macOS metadata)\n",
    "        if not filename.startswith('._') and os.path.exists(new_path):\n",
    "            valid_data.append(item)\n",
    "        else:\n",
    "            missing_count += 1\n",
    "    \n",
    "    # Save back in JSONL format (only valid files)\n",
    "    with open(manifest_path, 'w') as f:\n",
    "        for item in valid_data:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    print(f\"  ‚úÖ Fixed {fixed_count} paths\")\n",
    "    print(f\"  ‚úÖ Kept {len(valid_data)} valid files\")\n",
    "    if missing_count > 0:\n",
    "        print(f\"  ‚ö†Ô∏è  Removed {missing_count} missing files\")\n",
    "    \n",
    "    # Show example\n",
    "    if valid_data:\n",
    "        print(f\"  Example: {valid_data[0]['audio_filepath']}\")\n",
    "    \n",
    "    return len(valid_data)\n",
    "\n",
    "# Fix both manifests\n",
    "print(\"=\"*60)\n",
    "train_count = fix_manifest_paths('data/konkani-asr-v0/splits/manifests/train.json')\n",
    "val_count = fix_manifest_paths('data/konkani-asr-v0/splits/manifests/val.json')\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n‚úÖ Manifest paths fixed!\")\n",
    "print(f\"   Training samples: {train_count}\")\n",
    "print(f\"   Validation samples: {val_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Enable Multi-GPU Training (Optional)\n",
    "\n",
    "If you selected GPU T4 x2, this will enable both GPUs for faster training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check available GPUs\n",
    "gpu_count = torch.cuda.device_count()\n",
    "print(f\"Available GPUs: {gpu_count}\")\n",
    "\n",
    "if gpu_count > 1:\n",
    "    print(f\"\\n‚úÖ Multi-GPU detected! Will use {gpu_count} GPUs\")\n",
    "    print(\"   This will speed up training significantly!\")\n",
    "    \n",
    "    for i in range(gpu_count):\n",
    "        print(f\"   GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    \n",
    "    # Patch the training script to use DataParallel\n",
    "    with open('training_scripts/train_konkanivani_asr.py', 'r') as f:\n",
    "        script = f.read()\n",
    "    \n",
    "    # Add DataParallel wrapper after model.to(device)\n",
    "    if 'torch.nn.DataParallel' not in script:\n",
    "        script = script.replace(\n",
    "            'self.model = model.to(device)',\n",
    "            '''self.model = model.to(device)\n",
    "        # Enable multi-GPU training\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(f\"Using {torch.cuda.device_count()} GPUs for training!\")\n",
    "            self.model = torch.nn.DataParallel(self.model)'''\n",
    "        )\n",
    "        \n",
    "        with open('training_scripts/train_konkanivani_asr.py', 'w') as f:\n",
    "            f.write(script)\n",
    "        \n",
    "        print(\"\\n‚úÖ Multi-GPU training enabled!\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ Multi-GPU already enabled\")\n",
    "    \n",
    "    # Increase batch size for multi-GPU\n",
    "    BATCH_SIZE = BATCH_SIZE * gpu_count\n",
    "    print(f\"\\nüìà Increased batch size to {BATCH_SIZE} (x{gpu_count})\")\n",
    "    print(f\"   Effective batch size: {BATCH_SIZE * GRAD_ACCUM}\")\n",
    "    \n",
    "elif gpu_count == 1:\n",
    "    print(\"\\n‚úÖ Single GPU mode\")\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No GPU detected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Add Project to Python Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project directory to Python path\n",
    "project_dir = os.getcwd()\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.insert(0, project_dir)\n",
    "    print(f\"‚úÖ Added to Python path: {project_dir}\")\n",
    "\n",
    "# Verify imports work\n",
    "try:\n",
    "    from models.konkanivani_asr import create_konkanivani_model\n",
    "    from data.audio_processing.dataset import KonkaniASRDataset\n",
    "    print(\"‚úÖ All imports working!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(f\"\\nCurrent directory: {os.getcwd()}\")\n",
    "    print(f\"Python path: {sys.path[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: üöÄ START TRAINING\n",
    "\n",
    "### Kaggle Advantages:\n",
    "- **30 hours GPU/week** (vs Colab's 12h)\n",
    "- **P100 with 16GB** (can use larger batch size)\n",
    "- **Auto-saves outputs** (checkpoints persist)\n",
    "- **Can restart** and continue training\n",
    "\n",
    "### Configuration:\n",
    "- Batch size: Auto-detected based on GPU\n",
    "- Mixed precision: FP16\n",
    "- Resume from: Epoch 15\n",
    "- Target: Epoch 50\n",
    "\n",
    "**Note**: You can turn OFF internet after this cell starts to save your 9h/week quota!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üöÄ STARTING KONKANIVANI ASR TRAINING ON KAGGLE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Gradient accumulation: {GRAD_ACCUM}x\")\n",
    "print(f\"Effective batch size: {BATCH_SIZE * GRAD_ACCUM}\")\n",
    "print(f\"Mixed precision: FP16\")\n",
    "print(f\"Resume from: Epoch 15\")\n",
    "print(f\"Target: Epoch 50\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüí° TIP: Turn OFF internet now to save your quota!\")\n",
    "print(\"   (Settings ‚Üí Internet ‚Üí OFF)\\n\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Set PYTHONPATH so the training script can find modules\n",
    "import os\n",
    "os.environ['PYTHONPATH'] = os.getcwd()\n",
    "\n",
    "!PYTHONPATH={os.getcwd()} python3 training_scripts/train_konkanivani_asr.py \\\n",
    "    --train_manifest data/konkani-asr-v0/splits/manifests/train.json \\\n",
    "    --val_manifest data/konkani-asr-v0/splits/manifests/val.json \\\n",
    "    --vocab_file data/vocab.json \\\n",
    "    --batch_size {BATCH_SIZE} \\\n",
    "    --gradient_accumulation_steps {GRAD_ACCUM} \\\n",
    "    --num_epochs 50 \\\n",
    "    --learning_rate 0.0005 \\\n",
    "    --device cuda \\\n",
    "    --d_model 256 \\\n",
    "    --encoder_layers 12 \\\n",
    "    --decoder_layers 6 \\\n",
    "    --mixed_precision \\\n",
    "    --checkpoint_dir checkpoints \\\n",
    "    --log_dir logs \\\n",
    "    --resume checkpoints/checkpoint_epoch_15.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14: Monitor GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 15: Check Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List checkpoints\n",
    "print(\"Saved checkpoints:\\n\")\n",
    "!ls -lh checkpoints/\n",
    "\n",
    "# Check latest checkpoint\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "checkpoints = sorted(Path('checkpoints').glob('checkpoint_epoch_*.pt'))\n",
    "if checkpoints:\n",
    "    latest = checkpoints[-1]\n",
    "    ckpt = torch.load(latest, map_location='cpu')\n",
    "    print(f\"\\nLatest checkpoint: {latest.name}\")\n",
    "    print(f\"Epoch: {ckpt['epoch']}\")\n",
    "    print(f\"Val loss: {ckpt.get('val_loss', 'N/A')}\")\n",
    "else:\n",
    "    print(\"\\nNo checkpoints saved yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 16: Download Checkpoints\n",
    "\n",
    "**Note**: Kaggle auto-saves outputs, but you can also download manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoints are automatically saved to /kaggle/working/checkpoints/\n",
    "# They will be available in the \"Output\" tab after the notebook finishes\n",
    "\n",
    "print(\"üì¶ Checkpoints will be available in the Output tab\")\n",
    "print(\"\\nTo download:\")\n",
    "print(\"  1. Wait for training to complete (or stop notebook)\")\n",
    "print(\"  2. Go to Output tab\")\n",
    "print(\"  3. Download checkpoints/ folder\")\n",
    "print(\"\\nCurrent checkpoints:\")\n",
    "!ls -lh checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîÑ To Continue Training After Session Ends\n",
    "\n",
    "Kaggle sessions last 12 hours. To continue:\n",
    "\n",
    "1. **Download checkpoints** from Output tab\n",
    "2. **Upload to your dataset** (update it with latest checkpoint)\n",
    "3. **Start new session** and run this notebook again\n",
    "4. It will **resume from latest checkpoint** automatically\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Kaggle vs Colab Summary\n",
    "\n",
    "### Kaggle Wins:\n",
    "- ‚úÖ 30h GPU/week (vs 12h)\n",
    "- ‚úÖ P100 with 16GB (vs T4 with 15GB)\n",
    "- ‚úÖ Auto-saves outputs\n",
    "- ‚úÖ Better for long training\n",
    "\n",
    "### Colab Wins:\n",
    "- ‚úÖ 90min idle timeout (vs 20min)\n",
    "- ‚úÖ Always-on internet\n",
    "- ‚úÖ More storage (100GB vs 20GB)\n",
    "\n",
    "### Recommendation:\n",
    "**Use Kaggle** for this training! The 30h/week and P100 GPU make it ideal for your 8-12 hour training run.\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Kaggle Tips\n",
    "\n",
    "1. **Turn off internet** after setup to save quota (9h/week)\n",
    "2. **Enable GPU** in notebook settings (P100 preferred)\n",
    "3. **Save outputs** - Kaggle auto-saves /kaggle/working/\n",
    "4. **Use datasets** - Upload once, use many times\n",
    "5. **Monitor quota** - Check GPU hours remaining\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
