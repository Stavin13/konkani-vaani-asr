{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéôÔ∏è KonkaniVani ASR Training - Google One + Colab\n",
    "\n",
    "**Resume training from Epoch 15 using your Google One storage**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö° Quick Start\n",
    "\n",
    "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí GPU (T4)\n",
    "2. **Run cells in order** (1 ‚Üí 8)\n",
    "3. **Keep browser tab open** during training (~12 hours)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Cell 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì¶ Installing dependencies...\\n\")\n",
    "!pip install -q torch torchaudio tensorboard jiwer pyyaml soundfile\n",
    "print(\"‚úÖ Dependencies installed!\\n\")\n",
    "\n",
    "# Verify GPU\n",
    "print(\"üîç Checking GPU...\\n\")\n",
    "!nvidia-smi --query-gpu=name,memory.total --format=csv,noheader\n",
    "print(\"\\n‚úÖ If you see 'Tesla T4' above, you're good to go!\")\n",
    "print(\"   If not, go to Runtime ‚Üí Change runtime type ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Cell 2: Mount Google Drive & Verify Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìÇ VERIFYING YOUR GOOGLE ONE DRIVE FILES\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Define paths\n",
    "base_path = \"/content/drive/MyDrive/konkanivani_training\"\n",
    "audio_path = f\"{base_path}/konkani-asr-v0/data/processed_segments_diarized/audio_segments\"\n",
    "manifest_path = f\"{base_path}/konkani-asr-v0/splits/manifests\"\n",
    "checkpoint_path = f\"{base_path}/checkpoint_epoch_15.pt\"\n",
    "vocab_path = f\"{base_path}/vocab.json\"\n",
    "\n",
    "all_good = True\n",
    "\n",
    "# Check audio files\n",
    "if os.path.exists(audio_path):\n",
    "    audio_files = [f for f in os.listdir(audio_path) if f.endswith('.wav')]\n",
    "    print(f\"‚úÖ Audio files: {len(audio_files)} files\")\n",
    "    if len(audio_files) < 100:\n",
    "        print(f\"   ‚ö†Ô∏è  Warning: Expected ~2500+ files, found {len(audio_files)}\")\n",
    "        all_good = False\n",
    "else:\n",
    "    print(f\"‚ùå Audio files NOT FOUND\")\n",
    "    print(f\"   Expected at: {audio_path}\")\n",
    "    all_good = False\n",
    "\n",
    "# Check manifests\n",
    "if os.path.exists(manifest_path):\n",
    "    manifests = ['train.json', 'val.json', 'test.json']\n",
    "    found_manifests = [m for m in manifests if os.path.exists(f\"{manifest_path}/{m}\")]\n",
    "    print(f\"‚úÖ Manifests: {', '.join(found_manifests)}\")\n",
    "    if len(found_manifests) < 2:\n",
    "        print(f\"   ‚ö†Ô∏è  Warning: Need at least train.json and val.json\")\n",
    "        all_good = False\n",
    "else:\n",
    "    print(f\"‚ùå Manifests NOT FOUND\")\n",
    "    print(f\"   Expected at: {manifest_path}\")\n",
    "    all_good = False\n",
    "\n",
    "# Check checkpoint\n",
    "if os.path.exists(checkpoint_path):\n",
    "    size_mb = os.path.getsize(checkpoint_path) / (1024*1024)\n",
    "    print(f\"‚úÖ Checkpoint: checkpoint_epoch_15.pt ({size_mb:.1f} MB)\")\n",
    "    if size_mb < 200:\n",
    "        print(f\"   ‚ö†Ô∏è  Warning: File seems too small, might be corrupted\")\n",
    "        all_good = False\n",
    "else:\n",
    "    print(f\"‚ùå Checkpoint NOT FOUND\")\n",
    "    print(f\"   Expected at: {checkpoint_path}\")\n",
    "    all_good = False\n",
    "\n",
    "# Check vocab\n",
    "if os.path.exists(vocab_path):\n",
    "    print(f\"‚úÖ Vocabulary: vocab.json\")\n",
    "else:\n",
    "    print(f\"‚ùå Vocab NOT FOUND\")\n",
    "    print(f\"   Expected at: {vocab_path}\")\n",
    "    all_good = False\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "if all_good:\n",
    "    print(\"‚úÖ ALL FILES VERIFIED! Ready to proceed.\")\n",
    "else:\n",
    "    print(\"‚ùå SOME FILES ARE MISSING!\")\n",
    "    print(\"   Please upload missing files to your Google Drive.\")\n",
    "    print(\"   See: GOOGLE_ONE_SETUP_GUIDE.md for instructions.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì§ Cell 3: Upload Code Package\n",
    "\n",
    "**Upload `konkani_code.zip` (38MB) from your Mac**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"üì§ Please upload: konkani_code.zip\")\n",
    "print(\"   Location on your Mac: /Volumes/data&proj/konkani/konkani_code.zip\")\n",
    "print(\"   Size: ~38MB\\n\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "if 'konkani_code.zip' in uploaded:\n",
    "    print(\"\\nüìÇ Extracting code...\")\n",
    "    !unzip -q konkani_code.zip -d /content/\n",
    "    print(\"‚úÖ Code extracted!\\n\")\n",
    "    \n",
    "    # Verify extraction\n",
    "    print(\"üìã Verifying extracted files:\\n\")\n",
    "    \n",
    "    checks = [\n",
    "        (\"/content/train_konkanivani_asr.py\", \"Training script\"),\n",
    "        (\"/content/models/konkanivani_asr.py\", \"Model definition\"),\n",
    "        (\"/content/data/audio_processing/dataset.py\", \"Dataset loader\"),\n",
    "        (\"/content/data/konkani-asr-v0/splits/manifests/train.json\", \"Train manifest\"),\n",
    "        (\"/content/vocab.json\", \"Vocabulary\")\n",
    "    ]\n",
    "    \n",
    "    all_present = True\n",
    "    for path, name in checks:\n",
    "        if os.path.exists(path):\n",
    "            print(f\"‚úÖ {name}\")\n",
    "        else:\n",
    "            print(f\"‚ùå {name} - NOT FOUND: {path}\")\n",
    "            all_present = False\n",
    "    \n",
    "    if all_present:\n",
    "        print(\"\\n‚úÖ All code files present! Ready for next step.\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Some files missing! Check your konkani_code.zip\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Please upload konkani_code.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîó Cell 4: Link Data from Google Drive\n",
    "\n",
    "**This creates symbolic links (instant, no copying!)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"üîó Setting up data links...\\n\")\n",
    "\n",
    "# Create directory structure\n",
    "!mkdir -p /content/data/konkani-asr-v0/data/processed_segments_diarized\n",
    "!mkdir -p /content/checkpoints\n",
    "!mkdir -p /content/logs\n",
    "\n",
    "base_path = \"/content/drive/MyDrive/konkanivani_training\"\n",
    "\n",
    "# Link audio files (instant!)\n",
    "drive_audio = f\"{base_path}/konkani-asr-v0/data/processed_segments_diarized/audio_segments\"\n",
    "local_audio = \"/content/data/konkani-asr-v0/data/processed_segments_diarized/audio_segments\"\n",
    "\n",
    "if os.path.exists(drive_audio):\n",
    "    !ln -s {drive_audio} {local_audio}\n",
    "    audio_count = len([f for f in os.listdir(drive_audio) if f.endswith('.wav')])\n",
    "    print(f\"‚úÖ Linked {audio_count} audio files (instant, no copying!)\")\n",
    "else:\n",
    "    print(f\"‚ùå Audio path not found: {drive_audio}\")\n",
    "\n",
    "# Copy checkpoint (small file)\n",
    "drive_checkpoint = f\"{base_path}/checkpoint_epoch_15.pt\"\n",
    "if os.path.exists(drive_checkpoint):\n",
    "    !cp {drive_checkpoint} /content/checkpoints/\n",
    "    size_mb = os.path.getsize('/content/checkpoints/checkpoint_epoch_15.pt') / (1024*1024)\n",
    "    print(f\"‚úÖ Copied checkpoint ({size_mb:.1f} MB)\")\n",
    "else:\n",
    "    print(f\"‚ùå Checkpoint not found: {drive_checkpoint}\")\n",
    "\n",
    "# Verify manifests from zip\n",
    "manifest_path = \"/content/data/konkani-asr-v0/splits/manifests\"\n",
    "if os.path.exists(f\"{manifest_path}/train.json\"):\n",
    "    print(f\"‚úÖ Manifests ready (from code zip)\")\n",
    "else:\n",
    "    print(f\"‚ùå Manifests not found in code zip\")\n",
    "\n",
    "# Verify vocab from zip\n",
    "if os.path.exists(\"/content/vocab.json\"):\n",
    "    print(f\"‚úÖ Vocabulary ready (from code zip)\")\n",
    "else:\n",
    "    print(f\"‚ùå Vocab not found in code zip\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ SETUP COMPLETE! Ready to train.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Cell 5: Start Training (Resume from Epoch 15)\n",
    "\n",
    "**This will run for ~12 hours. Keep this tab open!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üöÄ STARTING KONKANIVANI ASR TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check for checkpoint\n",
    "checkpoint_path = \"/content/checkpoints/checkpoint_epoch_15.pt\"\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(\"\\n‚úÖ Found checkpoint: checkpoint_epoch_15.pt\")\n",
    "    print(\"   Resuming from Epoch 16\")\n",
    "    print(\"   Training epochs: 16 ‚Üí 50 (35 epochs remaining)\")\n",
    "    print(\"   Estimated time: ~12 hours\\n\")\n",
    "    resume_flag = f\"--resume {checkpoint_path}\"\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No checkpoint found, starting from scratch\")\n",
    "    print(\"   Training epochs: 1 ‚Üí 50\")\n",
    "    print(\"   Estimated time: ~20 hours\\n\")\n",
    "    resume_flag = \"\"\n",
    "\n",
    "print(\"üìä Training configuration:\")\n",
    "print(\"   ‚Ä¢ Device: CUDA (Tesla T4 GPU)\")\n",
    "print(\"   ‚Ä¢ Batch size: 16\")\n",
    "print(\"   ‚Ä¢ Model: d_model=256, 12 encoder layers, 6 decoder layers\")\n",
    "print(\"   ‚Ä¢ Checkpoints saved every 5 epochs\")\n",
    "print(\"   ‚Ä¢ Best model saved when validation improves\\n\")\n",
    "\n",
    "print(\"‚è∞ Training will start in 5 seconds...\\n\")\n",
    "import time\n",
    "time.sleep(5)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING STARTED - DO NOT CLOSE THIS TAB!\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Start training\n",
    "!python3 /content/train_konkanivani_asr.py \\\n",
    "    --train_manifest /content/data/konkani-asr-v0/splits/manifests/train.json \\\n",
    "    --val_manifest /content/data/konkani-asr-v0/splits/manifests/val.json \\\n",
    "    --vocab_file /content/vocab.json \\\n",
    "    --batch_size 16 \\\n",
    "    --num_epochs 50 \\\n",
    "    --learning_rate 0.0005 \\\n",
    "    --device cuda \\\n",
    "    --d_model 256 \\\n",
    "    --encoder_layers 12 \\\n",
    "    --decoder_layers 6 \\\n",
    "    --checkpoint_dir /content/checkpoints \\\n",
    "    --log_dir /content/logs \\\n",
    "    {resume_flag}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Cell 6: Monitor Training Progress\n",
    "\n",
    "**Run this in a separate cell while training is running**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"üìä Training Status - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check checkpoints\n",
    "print(\"\\nüíæ Saved Checkpoints:\\n\")\n",
    "!ls -lth /content/checkpoints/ | head -8\n",
    "\n",
    "# Check GPU usage\n",
    "print(\"\\nüî• GPU Usage:\\n\")\n",
    "!nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total,temperature.gpu --format=csv,noheader\n",
    "\n",
    "# Check latest log\n",
    "print(\"\\nüìù Recent Training Log:\\n\")\n",
    "!tail -30 /content/logs/training.log 2>/dev/null || echo \"Log file not created yet\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Cell 7: Backup Checkpoints to Drive\n",
    "\n",
    "**Run this every 2-3 hours to save progress**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "backup_path = f\"/content/drive/MyDrive/konkanivani_training/backups/backup_{timestamp}\"\n",
    "\n",
    "print(f\"üíæ Backing up to Google Drive...\\n\")\n",
    "print(f\"Backup location: {backup_path}\\n\")\n",
    "\n",
    "!mkdir -p {backup_path}\n",
    "\n",
    "# Copy checkpoints\n",
    "!cp -r /content/checkpoints/* {backup_path}/ 2>/dev/null\n",
    "\n",
    "# Copy logs\n",
    "!cp -r /content/logs {backup_path}/ 2>/dev/null\n",
    "\n",
    "print(\"‚úÖ Backup complete!\\n\")\n",
    "print(\"üìã Backed up files:\\n\")\n",
    "!ls -lh {backup_path}/\n",
    "\n",
    "print(f\"\\nüí° Tip: Run this cell every 2-3 hours to save your progress!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Cell 8: Download Final Model\n",
    "\n",
    "**Run this after training completes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üì¶ Preparing final model package...\\n\")\n",
    "\n",
    "# Create package directory\n",
    "!mkdir -p /content/final_model\n",
    "\n",
    "# Copy best model\n",
    "if os.path.exists('/content/checkpoints/best_model.pt'):\n",
    "    !cp /content/checkpoints/best_model.pt /content/final_model/\n",
    "    print(\"‚úÖ Copied best_model.pt\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  best_model.pt not found, using latest checkpoint\")\n",
    "    !cp /content/checkpoints/checkpoint_epoch_*.pt /content/final_model/ 2>/dev/null | tail -1\n",
    "\n",
    "# Copy supporting files\n",
    "!cp /content/vocab.json /content/final_model/\n",
    "!cp -r /content/models /content/final_model/\n",
    "!cp /content/inference_konkanivani.py /content/final_model/ 2>/dev/null\n",
    "\n",
    "print(\"‚úÖ Copied supporting files\\n\")\n",
    "\n",
    "# Create zip\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "zip_name = f\"konkanivani_final_model_{timestamp}.zip\"\n",
    "\n",
    "!cd /content && zip -r {zip_name} final_model/\n",
    "\n",
    "print(f\"\\nüì¶ Package created: {zip_name}\")\n",
    "print(f\"   Size: \", end=\"\")\n",
    "!ls -lh /content/{zip_name} | awk '{print $5}'\n",
    "\n",
    "# Also save to Drive\n",
    "drive_path = \"/content/drive/MyDrive/konkanivani_training/final_models\"\n",
    "!mkdir -p {drive_path}\n",
    "!cp /content/{zip_name} {drive_path}/\n",
    "print(f\"\\n‚úÖ Saved to Drive: {drive_path}/{zip_name}\")\n",
    "\n",
    "# Download\n",
    "print(f\"\\nüì• Downloading to your computer...\")\n",
    "files.download(f'/content/{zip_name}')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ TRAINING COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nYour model is ready to use!\")\n",
    "print(\"Extract the zip and use inference_konkanivani.py to test it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîß Troubleshooting\n",
    "\n",
    "### Training stopped / Runtime disconnected\n",
    "```python\n",
    "# Just re-run Cell 5 - it will resume from the latest checkpoint\n",
    "```\n",
    "\n",
    "### Out of memory error\n",
    "```python\n",
    "# In Cell 5, change:\n",
    "--batch_size 16  ‚Üí  --batch_size 8\n",
    "```\n",
    "\n",
    "### Can't find files in Drive\n",
    "```python\n",
    "# Check your folder structure:\n",
    "!ls -la /content/drive/MyDrive/konkanivani_training/\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Tips\n",
    "\n",
    "1. **Keep tab open**: Colab disconnects after 90 min of inactivity\n",
    "2. **Backup regularly**: Run Cell 7 every 2-3 hours\n",
    "3. **Monitor progress**: Run Cell 6 to check status\n",
    "4. **GPU usage**: Should be 90-100% during training\n",
    "5. **Checkpoints**: Saved every 5 epochs automatically\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
