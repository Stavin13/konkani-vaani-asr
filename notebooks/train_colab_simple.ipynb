{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KonkaniVani ASR Training - Simple Colab Setup\n",
    "## Resume from Checkpoint 15\n",
    "\n",
    "**Prerequisites**: Upload your entire project folder to Colab or extract from zip\n",
    "\n",
    "**Configuration:**\n",
    "- Model: d_model=256, 12 encoder, 6 decoder layers\n",
    "- Batch size: 2 (gradient accumulation 4x)\n",
    "- Mixed precision: FP16\n",
    "- GPU: Tesla T4 (14GB)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload Project Files\n",
    "\n",
    "Choose ONE option below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION A: Upload ZIP file and extract\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "\n",
    "print(\"üì§ Upload your konkani_project.zip file...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Extract\n",
    "for filename in uploaded.keys():\n",
    "    print(f\"\\nüì¶ Extracting {filename}...\")\n",
    "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall('/content/')\n",
    "    print(\"‚úÖ Extracted!\")\n",
    "\n",
    "!ls -la /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION B: Mount Drive and copy\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Update this path to your Drive location\n",
    "DRIVE_PATH = \"/content/drive/MyDrive/konkani_project.zip\"\n",
    "\n",
    "!cp {DRIVE_PATH} /content/\n",
    "!unzip -q /content/konkani_project.zip -d /content/\n",
    "!ls -la /content/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Navigate to Project Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Find the project directory\n",
    "# Update this if your folder has a different name\n",
    "possible_dirs = [\n",
    "    '/content/konkani',\n",
    "    '/content/konkani_project',\n",
    "    '/content',\n",
    "]\n",
    "\n",
    "project_dir = None\n",
    "for dir_path in possible_dirs:\n",
    "    if os.path.exists(f\"{dir_path}/training_scripts/train_konkanivani_asr.py\"):\n",
    "        project_dir = dir_path\n",
    "        break\n",
    "\n",
    "if project_dir:\n",
    "    print(f\"‚úÖ Found project at: {project_dir}\")\n",
    "    %cd {project_dir}\n",
    "else:\n",
    "    print(\"‚ùå Project not found. Please check the extracted folder name.\")\n",
    "    print(\"\\nAvailable directories:\")\n",
    "    !ls -la /content/\n",
    "    \n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch torchaudio librosa soundfile tensorboard tqdm pyyaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verify Project Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "required_files = [\n",
    "    'training_scripts/train_konkanivani_asr.py',\n",
    "    'models/konkanivani_asr.py',\n",
    "    'data/audio_processing/dataset.py',\n",
    "    'data/audio_processing/text_tokenizer.py',\n",
    "    'data/vocab.json',\n",
    "    'data/konkani-asr-v0/splits/manifests/train.json',\n",
    "    'data/konkani-asr-v0/splits/manifests/val.json',\n",
    "    'archives/checkpoint_epoch_15.pt'\n",
    "]\n",
    "\n",
    "print(\"Checking required files...\\n\")\n",
    "all_good = True\n",
    "for file in required_files:\n",
    "    exists = os.path.exists(file)\n",
    "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "    print(f\"{status} {file}\")\n",
    "    if not exists:\n",
    "        all_good = False\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if all_good:\n",
    "    print(\"‚úÖ All required files found! Ready to train.\")\n",
    "else:\n",
    "    print(\"‚ùå Some files are missing.\")\n",
    "    print(\"\\nMake sure your zip/folder contains:\")\n",
    "    print(\"  - training_scripts/\")\n",
    "    print(\"  - models/\")\n",
    "    print(\"  - data/\")\n",
    "    print(\"  - archives/checkpoint_epoch_15.pt\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prepare Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p checkpoints\n",
    "!cp archives/checkpoint_epoch_15.pt checkpoints/\n",
    "!ls -lh checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Verify Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "\n",
    "checkpoint = torch.load('checkpoints/checkpoint_epoch_15.pt', map_location='cpu')\n",
    "\n",
    "print(\"üìã Checkpoint Configuration:\")\n",
    "print(\"=\"*60)\n",
    "print(json.dumps(checkpoint.get('config', {}), indent=2))\n",
    "\n",
    "print(\"\\nüìä Model Architecture:\")\n",
    "print(\"=\"*60)\n",
    "state = checkpoint['model_state_dict']\n",
    "encoder_layers = sum(1 for k in state.keys() if 'encoder.layers.' in k and '.ff1.0.weight' in k)\n",
    "decoder_layers = sum(1 for k in state.keys() if 'decoder.decoder.layers.' in k and '.linear1.weight' in k)\n",
    "d_model = state['encoder.input_proj.weight'].shape[0]\n",
    "vocab_size = state['ctc_head.weight'].shape[0]\n",
    "\n",
    "print(f\"Encoder layers: {encoder_layers}\")\n",
    "print(f\"Decoder layers: {decoder_layers}\")\n",
    "print(f\"d_model: {d_model}\")\n",
    "print(f\"vocab_size: {vocab_size}\")\n",
    "print(f\"Epoch: {checkpoint['epoch']}\")\n",
    "print(f\"Val loss: {checkpoint.get('val_loss', 'N/A')}\")\n",
    "\n",
    "del checkpoint\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n‚úÖ Checkpoint verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '0'\n",
    "\n",
    "# Clear GPU memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Total memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"   Allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "    print(f\"   Cached: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
    "    print(\"\\n‚úÖ Ready to train!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è CUDA not available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. üöÄ START TRAINING\n",
    "\n",
    "### Configuration:\n",
    "- **Batch size**: 2 (reduced from 8 to fit in 14GB GPU)\n",
    "- **Gradient accumulation**: 4 steps (effective batch = 8)\n",
    "- **Mixed precision**: FP16 (saves ~50% memory)\n",
    "- **Model**: d_model=256, 12 encoder, 6 decoder layers\n",
    "- **Resume from**: Epoch 15\n",
    "- **Target**: Epochs 16-50\n",
    "\n",
    "**Expected time**: ~8-12 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 training_scripts/train_konkanivani_asr.py \\\n",
    "    --train_manifest data/konkani-asr-v0/splits/manifests/train.json \\\n",
    "    --val_manifest data/konkani-asr-v0/splits/manifests/val.json \\\n",
    "    --vocab_file data/vocab.json \\\n",
    "    --batch_size 2 \\\n",
    "    --gradient_accumulation_steps 4 \\\n",
    "    --num_epochs 50 \\\n",
    "    --learning_rate 0.0005 \\\n",
    "    --device cuda \\\n",
    "    --d_model 256 \\\n",
    "    --encoder_layers 12 \\\n",
    "    --decoder_layers 6 \\\n",
    "    --mixed_precision \\\n",
    "    --checkpoint_dir checkpoints \\\n",
    "    --log_dir logs \\\n",
    "    --resume checkpoints/checkpoint_epoch_15.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Monitor GPU (Run While Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. View TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Backup to Drive (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import time\n",
    "\n",
    "# Mount drive if not already mounted\n",
    "if not os.path.exists('/content/drive'):\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "BACKUP_PATH = \"/content/drive/MyDrive/konkanivani_backup\"\n",
    "\n",
    "print(f\"üì§ Backing up to: {BACKUP_PATH}\")\n",
    "print(f\"   Time: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "!mkdir -p {BACKUP_PATH}\n",
    "!cp -r checkpoints {BACKUP_PATH}/\n",
    "!cp -r logs {BACKUP_PATH}/\n",
    "\n",
    "print(\"\\n‚úÖ Backup completed!\")\n",
    "!ls -lh {BACKUP_PATH}/checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Download Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "from pathlib import Path\n",
    "\n",
    "!ls -lh checkpoints/\n",
    "\n",
    "if Path('checkpoints/best_model.pt').exists():\n",
    "    print(\"\\nüì• Downloading best_model.pt...\")\n",
    "    files.download('checkpoints/best_model.pt')\n",
    "    print(\"‚úÖ Downloaded!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è best_model.pt not found yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. If Out of Memory - Use This"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory\n",
    "import torch\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Run with batch_size=1\n",
    "!python3 training_scripts/train_konkanivani_asr.py \\\n",
    "    --train_manifest data/konkani-asr-v0/splits/manifests/train.json \\\n",
    "    --val_manifest data/konkani-asr-v0/splits/manifests/val.json \\\n",
    "    --vocab_file data/vocab.json \\\n",
    "    --batch_size 1 \\\n",
    "    --gradient_accumulation_steps 8 \\\n",
    "    --num_epochs 50 \\\n",
    "    --learning_rate 0.0005 \\\n",
    "    --device cuda \\\n",
    "    --d_model 256 \\\n",
    "    --encoder_layers 12 \\\n",
    "    --decoder_layers 6 \\\n",
    "    --mixed_precision \\\n",
    "    --checkpoint_dir checkpoints \\\n",
    "    --log_dir logs \\\n",
    "    --resume checkpoints/checkpoint_epoch_15.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Quick Reference\n",
    "\n",
    "### Check GPU\n",
    "```python\n",
    "!nvidia-smi\n",
    "```\n",
    "\n",
    "### Clear Memory\n",
    "```python\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "```\n",
    "\n",
    "### List Checkpoints\n",
    "```python\n",
    "!ls -lh checkpoints/\n",
    "```\n",
    "\n",
    "### Resume from Different Checkpoint\n",
    "```python\n",
    "# Change --resume to:\n",
    "--resume checkpoints/checkpoint_epoch_20.pt\n",
    "```\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
